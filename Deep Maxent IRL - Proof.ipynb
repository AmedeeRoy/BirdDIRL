{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep IRL\n",
    "\n",
    "Easy game formalism :\n",
    "\n",
    "- States = (x, t)\n",
    "- Action = (&uarr;, &darr;, &rarr;, &larr;)\n",
    "- Reward = r(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "FLOAT_MAX = 1e30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridworld provides a basic environment for RL agents to interact with\n",
    "\n",
    "class GridWorld:\n",
    "    \"\"\"\n",
    "    Grid world environment\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, length_max, height, width, start_pos):\n",
    "        \"\"\"\n",
    "            input: \n",
    "            height - idx : height of the spatial grid\n",
    "            width - idx : width of the spatial grid\n",
    "            length - idx : temporal length of a trip\n",
    "            \n",
    "            start_pos 2-tuple : coordinates within the state_space (height x width)\n",
    "            \n",
    "        \"\"\"\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.length_max = length_max\n",
    "        \n",
    "        self.start = (0, start_pos[0], start_pos[1])\n",
    "        self.end = (length_max-1, start_pos[0], start_pos[1])\n",
    "        \n",
    "        self.n_states = self.height*self.width*self.length_max\n",
    "        \n",
    "        self.actions = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "        self.n_actions = len(self.actions)\n",
    "        self.neighbors = [(0, 0),(-1, 0),(-1, 1),(0, 1),(1, 1),(1, 0),(1, -1),(0, -1),(-1, -1)]\n",
    "        self.dirs = {0: 'stay', 1: 'n', 2: 'ne', 3: 'e', 4: 'se', 5: 's', 6: 'sw', 7: 'w', 8: 'nw'}\n",
    "    \n",
    "    def get_grid_idx(self):\n",
    "        return np.array(range(self.n_states)).reshape((self.length_max, self.height, self.width))\n",
    "    \n",
    "    def get_list_state(self):\n",
    "        return [(i,j,k) for i in range(self.length_max) for j in range(self.height) for k in range(self.width)]\n",
    "    \n",
    "    def state2idx(self, state):\n",
    "        \"\"\"\n",
    "        input:\n",
    "          2d state\n",
    "        returns:\n",
    "          1d index\n",
    "        \"\"\"\n",
    "        return self.get_grid_idx()[state]\n",
    "\n",
    "    def idx2state(self, idx):\n",
    "        \"\"\"\n",
    "        input:\n",
    "          1d idx\n",
    "        returns:\n",
    "          2d state\n",
    "        \"\"\"\n",
    "        return self.get_list_state()[idx]\n",
    "           \n",
    "    def get_next_state(self, state, action):\n",
    "        \"\"\"\n",
    "        get next state with [action] on [state]\n",
    "        args\n",
    "          state     (z, y, x)\n",
    "          action    int\n",
    "        returns\n",
    "          new state\n",
    "        \"\"\"\n",
    "        if state[0] >= self.length_max-1:\n",
    "            return state\n",
    "        else :\n",
    "            inc = self.neighbors[action]\n",
    "            nei_s = (state[1] + inc[0], state[2] + inc[1])\n",
    "            if nei_s[0] >= 0 and nei_s[0] < self.height and nei_s[1] >= 0 and nei_s[1] < self.width:\n",
    "                next_state = (state[0] + 1, nei_s[0], nei_s[1])\n",
    "            else:\n",
    "                next_state = (state[0] + 1, state[1], state[2])\n",
    "            return next_state\n",
    "\n",
    "    def get_list_previous_state(self, state):\n",
    "        \"\"\"\n",
    "        args\n",
    "          state     (z, y, x)\n",
    "        returns\n",
    "          tuple\n",
    "              - previous state (z, y, x)\n",
    "              - associated action int\n",
    "        \"\"\"\n",
    "        previous = []\n",
    "        for a in self.actions:\n",
    "            inc = self.neighbors[a]\n",
    "            nei_s = (state[1] - inc[0], state[2] - inc[1])\n",
    "\n",
    "            if nei_s[0] >= 0 and nei_s[0] < self.height and nei_s[1] >= 0 and nei_s[1] < self.width:\n",
    "                previous_state = (state[0] - 1, nei_s[0], nei_s[1])\n",
    "                previous.append((previous_state,a))\n",
    "        return previous\n",
    "\n",
    "    def get_transition_mat(self):\n",
    "        \"\"\"\n",
    "        get transition dynamics of the gridworld\n",
    "        return:\n",
    "          P_a         NxNxN_ACTIONS transition probabilities matrix - \n",
    "                        P_a[s0, s1, a] is the transition prob of \n",
    "                        landing at state s1 when taking action \n",
    "                        a at state s0\n",
    "        \"\"\"\n",
    "        P_a = np.zeros((self.n_states, self.n_states, self.n_actions))\n",
    "        \n",
    "        for i in range(self.n_states):\n",
    "            si = self.idx2state(i)\n",
    "            for a in range(self.n_actions):\n",
    "                sj = self.get_next_state(si,a)\n",
    "                j = self.state2idx(sj)\n",
    "                P_a[i, j, a] = 1                \n",
    "        return P_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = GridWorld(5,3,4,(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]],\n",
       "\n",
       "       [[24, 25, 26, 27],\n",
       "        [28, 29, 30, 31],\n",
       "        [32, 33, 34, 35]],\n",
       "\n",
       "       [[36, 37, 38, 39],\n",
       "        [40, 41, 42, 43],\n",
       "        [44, 45, 46, 47]],\n",
       "\n",
       "       [[48, 49, 50, 51],\n",
       "        [52, 53, 54, 55],\n",
       "        [56, 57, 58, 59]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_grid_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(P_a, rewards, error=0.01, max_iter=100):\n",
    "    \"\"\"\n",
    "    static value iteration function. Perhaps the most useful function in this repo\n",
    "\n",
    "    inputs:\n",
    "    P_a         NxNxN_ACTIONS transition probabilities matrix - \n",
    "                          P_a[s0, s1, a] is the transition prob of \n",
    "                          landing at state s1 when taking action \n",
    "                          a at state s0\n",
    "    rewards     Nx1 matrix - rewards for all the states\n",
    "    gamma       float - RL discount\n",
    "    error       float - threshold for a stop\n",
    "\n",
    "    returns:\n",
    "    values    Nx1 matrix - estimated values\n",
    "    policy    Nx1 matrix - policy\n",
    "    \"\"\"\n",
    "    N_STATES, _, N_ACTIONS = np.shape(P_a)\n",
    "    n = 0 \n",
    "    values = np.ones([N_STATES])* -FLOAT_MAX\n",
    "    qvalues = np.ones((N_STATES, N_ACTIONS))* -FLOAT_MAX\n",
    "    policy = np.zeros((N_STATES, N_ACTIONS))\n",
    "        \n",
    "    # estimate values\n",
    "    while True:\n",
    "        values_tmp = values.copy()\n",
    "        values[g.state2idx(g.end)] = 0 # goal\n",
    "        \n",
    "        for s in range(N_STATES):\n",
    "            qvalues[s] = [sum([P_a[s, s1, a]*(rewards[s] + values[s1]) for s1 in range(N_STATES)]) for a in range(N_ACTIONS)]\n",
    "            \n",
    "            softmax = max(qvalues[s]) + np.log(1.0 + np.exp(min(qvalues[s]) - max(qvalues[s]))) \n",
    "            values[s] = rewards[s] + softmax\n",
    "            \n",
    "            policy[s,:] = np.exp(qvalues[s]-values[s])/sum(np.exp(qvalues[s]-values[s]))\n",
    "            \n",
    "        if max([abs(values[s] - values_tmp[s]) for s in range(N_STATES)]) < error:\n",
    "            break\n",
    "        n += 1\n",
    "        # max iteration\n",
    "        if n > max_iter:\n",
    "            print(\"    WARNING: max number of iterations\", max_iter)\n",
    "            break    \n",
    "    \n",
    "    return values, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.12589580e+00, -1.92243484e+00, -1.81022541e+00,\n",
       "         -1.04579154e+00],\n",
       "        [-2.63316394e+00, -7.02862612e-01, -9.81680963e-01,\n",
       "         -3.24363688e-01],\n",
       "        [-9.68738154e-01, -1.61891634e+00, -1.39873132e+00,\n",
       "         -8.32239973e-01]],\n",
       "\n",
       "       [[-2.32487325e+00, -9.18048749e-01, -1.36775978e-01,\n",
       "         -8.35731708e-01],\n",
       "        [-1.87140384e+00, -1.99541656e+00, -5.04602628e-01,\n",
       "         -5.31323382e-01],\n",
       "        [-1.15654903e+00, -1.67337113e+00, -1.35916901e+00,\n",
       "         -3.19609598e-01]],\n",
       "\n",
       "       [[-1.01302230e+00, -1.74232833e+00, -6.74015729e-01,\n",
       "         -1.23571213e+00],\n",
       "        [-1.13588841e+00, -1.03985182e+00, -7.14470928e-01,\n",
       "         -2.52812311e-01],\n",
       "        [-1.36610431e+00, -2.70308991e-01, -1.29095044e+00,\n",
       "         -5.82370265e-01]],\n",
       "\n",
       "       [[-5.55909288e-01, -1.30380188e+00, -1.79641239e+00,\n",
       "         -1.00000000e+30],\n",
       "        [-1.86817174e+00, -7.56399123e-02, -1.74911770e-01,\n",
       "         -1.00000000e+30],\n",
       "        [-6.64946905e-02, -8.36464552e-01, -5.10297820e-01,\n",
       "         -1.00000000e+30]],\n",
       "\n",
       "       [[-1.00000000e+30, -1.00000000e+30, -1.00000000e+30,\n",
       "         -1.00000000e+30],\n",
       "        [-1.00000000e+30, -7.25555858e-01, -1.00000000e+30,\n",
       "         -1.00000000e+30],\n",
       "        [-1.00000000e+30, -1.00000000e+30, -1.00000000e+30,\n",
       "         -1.00000000e+30]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = g.get_transition_mat()\n",
    "R = -np.random.random((g.n_states, 1))\n",
    "\n",
    "values, policy = value_iteration(P, R, 0.01, 100)\n",
    "\n",
    "values.reshape((g.length_max, g.height, g.width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0766463 , 0.0766463 , 0.0766463 , 0.31294448, 0.10655465,\n",
       "        0.12062309, 0.0766463 , 0.0766463 , 0.0766463 ],\n",
       "       [0.1153785 , 0.1153785 , 0.1153785 , 0.25201555, 0.17445453,\n",
       "        0.03928529, 0.04447214, 0.02825848, 0.1153785 ],\n",
       "       [0.15439166, 0.15439166, 0.15439166, 0.07674874, 0.10405767,\n",
       "        0.10687565, 0.02406725, 0.07068404, 0.15439166],\n",
       "       [0.09293669, 0.09293669, 0.09293669, 0.09293669, 0.09293669,\n",
       "        0.12600566, 0.12941802, 0.18695618, 0.09293669],\n",
       "       [0.08790374, 0.05585578, 0.22805742, 0.0776514 , 0.10715486,\n",
       "        0.17966557, 0.08790374, 0.08790374, 0.08790374],\n",
       "       [0.04499018, 0.13213341, 0.28861246, 0.19978827, 0.08500345,\n",
       "        0.06208408, 0.10409582, 0.05093025, 0.03236209],\n",
       "       [0.14363027, 0.20748708, 0.10314269, 0.13984318, 0.17281738,\n",
       "        0.06111003, 0.04463302, 0.032344  , 0.09499234],\n",
       "       [0.11209334, 0.08267552, 0.11209334, 0.11209334, 0.11209334,\n",
       "        0.13852429, 0.04898363, 0.11512893, 0.16631429],\n",
       "       [0.1330163 , 0.06507997, 0.0574896 , 0.07933263, 0.1330163 ,\n",
       "        0.1330163 , 0.1330163 , 0.1330163 , 0.1330163 ],\n",
       "       [0.08468194, 0.06136606, 0.2725088 , 0.11594368, 0.08468194,\n",
       "        0.08468194, 0.08468194, 0.14198544, 0.06946824],\n",
       "       [0.07857709, 0.18468406, 0.17981451, 0.22221372, 0.07857709,\n",
       "        0.07857709, 0.07857709, 0.05739046, 0.04158887],\n",
       "       [0.12509512, 0.10122651, 0.12509512, 0.12509512, 0.12509512,\n",
       "        0.12509512, 0.12509512, 0.04423494, 0.10396782],\n",
       "       [0.11990188, 0.11990188, 0.11990188, 0.05782191, 0.11672774,\n",
       "        0.10603907, 0.11990188, 0.11990188, 0.11990188],\n",
       "       [0.06397211, 0.06397211, 0.06397211, 0.18618853, 0.17880656,\n",
       "        0.12914343, 0.11731787, 0.13265519, 0.06397211],\n",
       "       [0.12358508, 0.12358508, 0.12358508, 0.07047327, 0.18831823,\n",
       "        0.1186852 , 0.08572065, 0.04246233, 0.12358508],\n",
       "       [0.08257669, 0.08257669, 0.08257669, 0.08257669, 0.08257669,\n",
       "        0.22066092, 0.13906878, 0.14481018, 0.08257669],\n",
       "       [0.10052711, 0.11366932, 0.05481629, 0.11066017, 0.23889087,\n",
       "        0.07985492, 0.10052711, 0.10052711, 0.10052711],\n",
       "       [0.10085113, 0.04995732, 0.14539899, 0.13963423, 0.0784567 ,\n",
       "        0.21771532, 0.07277649, 0.09161627, 0.10359354],\n",
       "       [0.11676684, 0.12158752, 0.06933417, 0.18527436, 0.13325702,\n",
       "        0.06560813, 0.18206086, 0.08433511, 0.04177599],\n",
       "       [0.14849853, 0.05557176, 0.14849853, 0.14849853, 0.14849853,\n",
       "        0.10680632, 0.05258532, 0.09358934, 0.09745314],\n",
       "       [0.08593872, 0.10818583, 0.11909089, 0.25709093, 0.08593872,\n",
       "        0.08593872, 0.08593872, 0.08593872, 0.08593872],\n",
       "       [0.16077089, 0.07447306, 0.10311227, 0.057936  , 0.16077089,\n",
       "        0.16077089, 0.16077089, 0.05374147, 0.06765362],\n",
       "       [0.06804928, 0.12111151, 0.19216806, 0.13821526, 0.06804928,\n",
       "        0.06804928, 0.06804928, 0.188835  , 0.08747305],\n",
       "       [0.11416895, 0.15873519, 0.11416895, 0.11416895, 0.11416895,\n",
       "        0.11416895, 0.11416895, 0.05621025, 0.10004086],\n",
       "       [0.11963034, 0.11963034, 0.11963034, 0.05662859, 0.19338362,\n",
       "        0.03220572, 0.11963034, 0.11963034, 0.11963034],\n",
       "       [0.0724666 , 0.0724666 , 0.0724666 , 0.04427921, 0.22408286,\n",
       "        0.2474696 , 0.04121309, 0.15308884, 0.0724666 ],\n",
       "       [0.06140203, 0.06140203, 0.06140203, 0.        , 0.        ,\n",
       "        0.31073596, 0.34316639, 0.10048952, 0.06140203],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.83500198, 0.16499802, 0.        ],\n",
       "       [0.04107924, 0.15259164, 0.07223125, 0.24666587, 0.11526226,\n",
       "        0.24893203, 0.04107924, 0.04107924, 0.04107924],\n",
       "       [0.18916595, 0.05539352, 0.03384706, 0.17128911, 0.12248233,\n",
       "        0.08839364, 0.19090385, 0.03150332, 0.11702122],\n",
       "       [0.25930437, 0.05123905, 0.        , 0.        , 0.        ,\n",
       "        0.1854187 , 0.13381387, 0.28636706, 0.08385696],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.37385657, 0.522831  , 0.10331243],\n",
       "       [0.13125176, 0.02165942, 0.13005691, 0.06077311, 0.13125176,\n",
       "        0.13125176, 0.13125176, 0.13125176, 0.13125176],\n",
       "       [0.08347535, 0.1786406 , 0.16175844, 0.11566731, 0.08347535,\n",
       "        0.08347535, 0.08347535, 0.1802818 , 0.02975045],\n",
       "       [0.13046996, 0.18245965, 0.        , 0.        , 0.13046996,\n",
       "        0.13046996, 0.13046996, 0.09415819, 0.20150232],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.41693069, 0.58306931],\n",
       "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_state_visition_freq(P_a, start_idx, nb_step, policy):\n",
    "    \"\"\"compute the expected states visition frequency p(s| theta, T) \n",
    "    using dynamic programming\n",
    "    inputs:\n",
    "    P_a     NxNxN_ACTIONS matrix - transition dynamics\n",
    "    gamma   float - discount factor\n",
    "    start_idx   idx of start position\n",
    "    nb_step idx - nb of step to iterate\n",
    "    policy  Nx1 vector - policy\n",
    "\n",
    "    returns:\n",
    "    p       Nx1 vector - state visitation frequencies\n",
    "    \"\"\"\n",
    "    N_STATES, _, N_ACTIONS = np.shape(P_a)\n",
    "\n",
    "    # mu[s, t] is the prob of visiting state s at time t\n",
    "    mu = np.zeros([N_STATES, nb_step]) \n",
    "\n",
    "    mu[start_idx, 0] = 1\n",
    "    for s in range(N_STATES):\n",
    "        for t in range(nb_step-1):\n",
    "            mu[s, t+1] = sum([sum([mu[pre_s, t]*P_a[pre_s, s, a1]*policy[pre_s, a1] for a1 in range(N_ACTIONS)]) for pre_s in range(N_STATES)])\n",
    "\n",
    "    p = np.sum(mu, 1)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.03236209, 0.13213341, 0.28861246, 0.        ],\n",
       "        [0.05093025, 0.04499018, 0.19978827, 0.        ],\n",
       "        [0.10409582, 0.06208408, 0.08500345, 0.        ]],\n",
       "\n",
       "       [[0.05125973, 0.06132355, 0.19810779, 0.03419162],\n",
       "        [0.05899647, 0.09706015, 0.10418769, 0.10770158],\n",
       "        [0.06435292, 0.14107442, 0.04337211, 0.03837196]],\n",
       "\n",
       "       [[0.06654173, 0.05896092, 0.07676438, 0.        ],\n",
       "        [0.0225209 , 0.198132  , 0.25690939, 0.        ],\n",
       "        [0.10932702, 0.08442104, 0.12642262, 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svf = compute_state_visition_freq(P, g.state2idx((0,1,1)), g.length_max, policy)\n",
    "svf.reshape((g.length_max, g.height, g.width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]],\n",
       "\n",
       "       [[24, 25, 26, 27],\n",
       "        [28, 29, 30, 31],\n",
       "        [32, 33, 34, 35]],\n",
       "\n",
       "       [[36, 37, 38, 39],\n",
       "        [40, 41, 42, 43],\n",
       "        [44, 45, 46, 47]],\n",
       "\n",
       "       [[48, 49, 50, 51],\n",
       "        [52, 53, 54, 55],\n",
       "        [56, 57, 58, 59]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_grid_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.],\n",
       "       [ 0., 12.,  4.,  0.],\n",
       "       [ 0.,  7.,  7.,  0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create expert trajectories\n",
    "\n",
    "traj_1 = [5, 18, 33, 46, 53]\n",
    "traj_2 = [5, 22, 30, 45, 53]\n",
    "traj_3 = [5, 21, 34, 45, 53]\n",
    "traj_4 = [5, 21, 33, 45, 53]\n",
    "traj_5 = [5, 22, 34, 42, 53]\n",
    "traj_6 = [5, 22, 34, 42, 53]\n",
    "\n",
    "trajs = [traj_1, traj_2, traj_3, traj_4, traj_5, traj_6]\n",
    "\n",
    "\n",
    "freq = np.zeros((3,4))\n",
    "for traj in trajs:\n",
    "    for idx in traj:\n",
    "        state = g.idx2state(idx)\n",
    "        freq[state[1], state[2]] += 1\n",
    "        \n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feat_map\n",
    "\n",
    "map_mask = [[-1, -1, -1, 0],\n",
    "            [-1, 0, 0, 0],\n",
    "            [-1, 0, 0, 0]]\n",
    "\n",
    "map_dist = [[-0.5, -0.5, -0.5, -1],\n",
    "            [-0.5, 0, -0.5, -1],\n",
    "            [-0.5, -0.5, -0.5, -1]]\n",
    "\n",
    "map_gradv = [[0, 0, 0, 0],\n",
    "            [-0.5, -0.5, -0.5, -0.5],\n",
    "            [-1, -1, -1, -1]]\n",
    "\n",
    "map_gradh = [[0, -0.3, -0.6, -0.9],\n",
    "            [0, -0.3, -0.6, -0.9],\n",
    "            [0, -0.3, -0.6, -0.9]]\n",
    "\n",
    "map_const = [[0, 0, 0, 0],\n",
    "            [0, 0, 0, 0],\n",
    "            [0, 0, 0, 0]]\n",
    "\n",
    "\n",
    "\n",
    "feat_map = np.array([map_mask, map_dist, map_gradv, map_gradh, map_const]).reshape(5,12).T\n",
    "for t in range(g.length_max-1):\n",
    "    feature =  np.array([map_mask, map_dist, map_gradv, map_gradh, map_const]).reshape(5,12).T\n",
    "    feature[:,4] -= 0.1*(t+1)\n",
    "    \n",
    "    feat_map = np.vstack([feat_map, feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. , -0.5,  0. ,  0. ,  0. ],\n",
       "       [-1. , -0.5,  0. , -0.3,  0. ],\n",
       "       [-1. , -0.5,  0. , -0.6,  0. ],\n",
       "       [ 0. , -1. ,  0. , -0.9,  0. ],\n",
       "       [-1. , -0.5, -0.5,  0. ,  0. ],\n",
       "       [ 0. ,  0. , -0.5, -0.3,  0. ],\n",
       "       [ 0. , -0.5, -0.5, -0.6,  0. ],\n",
       "       [ 0. , -1. , -0.5, -0.9,  0. ],\n",
       "       [-1. , -0.5, -1. ,  0. ,  0. ],\n",
       "       [ 0. , -0.5, -1. , -0.3,  0. ],\n",
       "       [ 0. , -0.5, -1. , -0.6,  0. ],\n",
       "       [ 0. , -1. , -1. , -0.9,  0. ],\n",
       "       [-1. , -0.5,  0. ,  0. , -0.1],\n",
       "       [-1. , -0.5,  0. , -0.3, -0.1],\n",
       "       [-1. , -0.5,  0. , -0.6, -0.1],\n",
       "       [ 0. , -1. ,  0. , -0.9, -0.1],\n",
       "       [-1. , -0.5, -0.5,  0. , -0.1],\n",
       "       [ 0. ,  0. , -0.5, -0.3, -0.1],\n",
       "       [ 0. , -0.5, -0.5, -0.6, -0.1],\n",
       "       [ 0. , -1. , -0.5, -0.9, -0.1],\n",
       "       [-1. , -0.5, -1. ,  0. , -0.1],\n",
       "       [ 0. , -0.5, -1. , -0.3, -0.1],\n",
       "       [ 0. , -0.5, -1. , -0.6, -0.1],\n",
       "       [ 0. , -1. , -1. , -0.9, -0.1],\n",
       "       [-1. , -0.5,  0. ,  0. , -0.2],\n",
       "       [-1. , -0.5,  0. , -0.3, -0.2],\n",
       "       [-1. , -0.5,  0. , -0.6, -0.2],\n",
       "       [ 0. , -1. ,  0. , -0.9, -0.2],\n",
       "       [-1. , -0.5, -0.5,  0. , -0.2],\n",
       "       [ 0. ,  0. , -0.5, -0.3, -0.2],\n",
       "       [ 0. , -0.5, -0.5, -0.6, -0.2],\n",
       "       [ 0. , -1. , -0.5, -0.9, -0.2],\n",
       "       [-1. , -0.5, -1. ,  0. , -0.2],\n",
       "       [ 0. , -0.5, -1. , -0.3, -0.2],\n",
       "       [ 0. , -0.5, -1. , -0.6, -0.2],\n",
       "       [ 0. , -1. , -1. , -0.9, -0.2],\n",
       "       [-1. , -0.5,  0. ,  0. , -0.3],\n",
       "       [-1. , -0.5,  0. , -0.3, -0.3],\n",
       "       [-1. , -0.5,  0. , -0.6, -0.3],\n",
       "       [ 0. , -1. ,  0. , -0.9, -0.3],\n",
       "       [-1. , -0.5, -0.5,  0. , -0.3],\n",
       "       [ 0. ,  0. , -0.5, -0.3, -0.3],\n",
       "       [ 0. , -0.5, -0.5, -0.6, -0.3],\n",
       "       [ 0. , -1. , -0.5, -0.9, -0.3],\n",
       "       [-1. , -0.5, -1. ,  0. , -0.3],\n",
       "       [ 0. , -0.5, -1. , -0.3, -0.3],\n",
       "       [ 0. , -0.5, -1. , -0.6, -0.3],\n",
       "       [ 0. , -1. , -1. , -0.9, -0.3],\n",
       "       [-1. , -0.5,  0. ,  0. , -0.4],\n",
       "       [-1. , -0.5,  0. , -0.3, -0.4],\n",
       "       [-1. , -0.5,  0. , -0.6, -0.4],\n",
       "       [ 0. , -1. ,  0. , -0.9, -0.4],\n",
       "       [-1. , -0.5, -0.5,  0. , -0.4],\n",
       "       [ 0. ,  0. , -0.5, -0.3, -0.4],\n",
       "       [ 0. , -0.5, -0.5, -0.6, -0.4],\n",
       "       [ 0. , -1. , -0.5, -0.9, -0.4],\n",
       "       [-1. , -0.5, -1. ,  0. , -0.4],\n",
       "       [ 0. , -0.5, -1. , -0.3, -0.4],\n",
       "       [ 0. , -0.5, -1. , -0.6, -0.4],\n",
       "       [ 0. , -1. , -1. , -0.9, -0.4]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxent_irl(feat_map, P_a, trajs, lr, error, max_iter):\n",
    "    \"\"\"\n",
    "    Maximum Entropy Inverse Reinforcement Learning (Maxent IRL)\n",
    "    inputs:\n",
    "    feat_map    NxD matrix - the features for each state\n",
    "    P_a         NxNxN_ACTIONS matrix - P_a[s0, s1, a] is the transition prob of \n",
    "                                       landing at state s1 when taking action \n",
    "                                       a at state s0\n",
    "    gamma       float - RL discount factor\n",
    "    trajs       a list of demonstrations\n",
    "    lr          float - learning rate\n",
    "    n_iters     int - number of optimization steps\n",
    "    returns\n",
    "    rewards     Nx1 vector - recoverred state rewards\n",
    "    \"\"\"\n",
    "    N_STATES, _, N_ACTIONS = np.shape(P_a)\n",
    "\n",
    "    # init parameters\n",
    "    theta = np.random.uniform(size=(feat_map.shape[1]))\n",
    "    \n",
    "    # calc feature expectations\n",
    "    feat_exp = np.zeros([feat_map.shape[1]])\n",
    "    for episode in trajs:\n",
    "        for step in episode:\n",
    "            feat_exp += feat_map[step,:]\n",
    "    feat_exp = feat_exp/len(trajs)\n",
    "\n",
    "    n = 0\n",
    "    error_history = []\n",
    "    # training\n",
    "    while True:\n",
    "        n += 1\n",
    "        if n % (max_iter/20) == 0:\n",
    "            print('iteration: {}/{}'.format(n, max_iter))\n",
    "\n",
    "        # compute reward function\n",
    "        rewards = np.dot(feat_map, theta)\n",
    "\n",
    "        # compute policy\n",
    "        _, policy = value_iteration(P_a, rewards, error=0.01, max_iter=100)\n",
    "\n",
    "        # compute state visition frequences\n",
    "        svf = compute_state_visition_freq(P_a, g.state2idx((0,1,1)), g.length_max, policy)\n",
    "        \n",
    "        # compute gradients\n",
    "        grad = feat_exp - feat_map.T.dot(svf)\n",
    "                \n",
    "        # update params\n",
    "        theta += lr * grad\n",
    "       \n",
    "        error_history.append(sum(grad**2))\n",
    "        \n",
    "        plt.plot(error_history)\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        IPython.display.display(plt.show())\n",
    "        \n",
    "        if sum(grad**2) < error:\n",
    "            break\n",
    "        # max iteration\n",
    "        if n > max_iter:\n",
    "            print(\"    WARNING: max number of iterations\", max_iter)\n",
    "            break \n",
    "            \n",
    "    rewards = np.dot(feat_map, theta)\n",
    "    return rewards, policy, error_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 5/100\n",
      "iteration: 10/100\n",
      "iteration: 15/100\n",
      "iteration: 20/100\n",
      "iteration: 25/100\n",
      "iteration: 30/100\n",
      "iteration: 35/100\n"
     ]
    }
   ],
   "source": [
    "rewards, policy, error_history = maxent_irl(feat_map, P, trajs, 0.1, 0.01, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f85c09b2790>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD7CAYAAAB68m/qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZxV9X3/8dfnLrMwKwzDviuLgII6ohHXaBrUCmmriSRpY01rk5Ysv6ZJTZc0pb+20bRZfv3xMzGJsUmTEmOaiAnRxLgkRlFGWWSVAYEZBmEEhgFmvTOf3x/3gtfhwlxgZs5d3s/HYx73nnPP3Hl7HvKeM997zvmauyMiItkvFHQAERHpHyp0EZEcoUIXEckRKnQRkRyhQhcRyREqdBGRHJFWoZvZAjPbamZ1ZnZPitcnmNnTZrbGzNab2c39H1VERE7H+joP3czCwGvAu4AGYDWw2N03JW3zALDG3e83s5nASnefNGCpRUTkJJE0tpkH1Ln7DgAzWw4sAjYlbeNAeeJ5BdDY15sOHz7cJ02adEZhRUTy3csvv/ymu1enei2dQh8L1CctNwCX99rm88AvzOxjQAlwY19vOmnSJGpra9P48SIicpyZ7TrVa+mMoVuKdb3HaRYDD7n7OOBm4LtmdtJ7m9ndZlZrZrVNTU1p/GgREUlXOoXeAIxPWh7HyUMqHwYeBnD3F4AiYHjvN3L3B9y9xt1rqqtT/sUgIiJnKZ1CXw1MNbPJZlYA3AGs6LXNbuAGADO7gHih6xBcRGQQ9Vno7h4DlgBPAJuBh919o5ktNbOFic0+Bfypma0D/hu403UbRxGRQZXOh6K4+0pgZa91n0t6vgmY37/RRETkTOhKURGRHKFCFxHJEVlX6C/vOsi9j29BQ/QiIm+XdYW+YU8L9z+znb2H24OOIiKSUbKu0C+eUAnAK7sPBZxERCSzZF2hzxhVTmEkxJrdzUFHERHJKFlX6AWREBeNq2CNjtBFRN4m6wod4OIJQ9nQ2EJHrDvoKCIiGSM7C318JZ2xHjY1tgQdRUQkY2RloV8ycSiAxtFFRJJkZaGPLC9iTEURa+pV6CIix2VloUN8HF0fjIqIvCWLC72ShkNt7D+iC4xERCCrC13j6CIiybK20GeNKScaNhW6iEhC1hZ6UTTMzDG6wEhE5LisLXSIn4++vuEwse6eoKOIiAQurUI3swVmttXM6szsnhSvf9nM1ia+XjOzQRkHuWTiUNq6utnyxpHB+HEiIhmtzynozCwMLAPeBTQAq81sRWLaOQDc/X8lbf8x4OIByHqSi8fH77y4pr6Z2WMrBuNHiohkrHSO0OcBde6+w907geXAotNsv5j4RNEDbtzQYoaXFrJml8bRRUTSKfSxQH3SckNi3UnMbCIwGXjq3KP1zcy4eEKlrhgVESG9QrcU6041/9sdwCPunvI2iGZ2t5nVmlltU1NTuhlP65IJQ3n9zWMcOtbZL+8nIpKt0in0BmB80vI4oPEU297BaYZb3P0Bd69x95rq6ur0U57G8RmM1uooXUTyXDqFvhqYamaTzayAeGmv6L2RmU0HhgIv9G/E07toXAUh05R0IiJ9Frq7x4AlwBPAZuBhd99oZkvNbGHSpouB5e5+quGYATGkIMKMUeW6YlRE8l6fpy0CuPtKYGWvdZ/rtfz5/ot1Zi6ZWMlP1jTS3eOEQ6mG/EVEcl9WXyl63MXjh3K0I8b2pqNBRxERCUxuFHrig9FXdD66iOSxnCj0ycNLqBwS1Ti6iOS1nCh0M+Pi8ZWsqdcRuojkr5wodIhPeLFt/1Fa2ruCjiIiEogcKvRK3GGdLjASkTyVM4U+Z3wlZpqSTkTyV84UenlRlKkjSjWDkYjkrZwpdIifj76mvplBvlhVRCQj5FahT6ikubWL1988FnQUEZFBl2OFPhTQOLqI5KecKvSpI0opK4zofHQRyUs5VeihkDFnfCWv7NIRuojkn5wqdIiPo295o4XWzljQUUREBlVOFnqPw/qGw0FHEREZVLlX6OPjH4y+rDsvikieyblCH1pSwIxRZTy37c2go4iIDKq0Ct3MFpjZVjOrM7N7TrHNe81sk5ltNLPv92/MM3Pt9Gpqdx3kaIfG0UUkf/RZ6GYWBpYBNwEzgcVmNrPXNlOBzwLz3X0W8MkByJq2a6dW09XtvLD9QJAxREQGVTpH6POAOnff4e6dwHJgUa9t/hRY5u6HANx9f//GPDOXThrKkIIwv36tKcgYIiKDKp1CHwvUJy03JNYlmwZMM7PfmtkqM1vQXwHPRmEkzDumVPGsCl1E8kg6hW4p1vW++1UEmApcBywGvmlmlSe9kdndZlZrZrVNTQNbttdOr2b3wVZ26r4uIpIn0in0BmB80vI4oDHFNo+6e5e7vw5sJV7wb+PuD7h7jbvXVFdXn23mtFw7Lf7+OkoXkXyRTqGvBqaa2WQzKwDuAFb02uYnwPUAZjac+BDMjv4MeqYmVpUwsWqIxtFFJG/0WejuHgOWAE8Am4GH3X2jmS01s4WJzZ4ADpjZJuBp4NPuHvgpJtdOq+b57QfoiHUHHUVEZMBF0tnI3VcCK3ut+1zScwf+MvGVMa6ZWs13XthF7c5DzD9/eNBxREQGVM5dKZrsHedVEQ2bhl1EJC/kdKGXFEa4bNIwfTAqInkhpwsd4Jpp1Wx54wj7WtqDjiIiMqByvtB1+qKI5IucL/QZo8oYUVaocXQRyXk5X+hmxjXTqvnNtjfp7ul9gauISO7I+UKH+LDL4bYu1jVorlERyV15UehXnT8cMzTsIiI5LS8KfWhJAXPGVeqDURHJaXlR6BA/fXFdfTPNrZ1BRxERGRB5U+jXTqumx+G5Os01KiK5KW8Kfc64CiqKoxpHF5GclTeFHgmHuOr84Tz7WhPxe4mJiOSWvCl0iA+77GvpYOu+I0FHERHpd3lV6FdPi99CV8MuIpKL8qrQR1cUM31kmU5fFJGclFeFDvHJo1e/fojWzljQUURE+lVahW5mC8xsq5nVmdk9KV6/08yazGxt4utP+j9q/7hmajWd3T2s2hH4DHkiIv2qz0I3szCwDLgJmAksNrOZKTb9gbvPTXx9s59z9puaSUMpjob59Ws6H11Ecks6R+jzgDp33+HuncByYNHAxho4RdEwV0wZxjNb9+v0RRHJKekU+ligPmm5IbGutz8ws/Vm9oiZje+XdAPkxpkj2Xmglc17dfqiiOSOdArdUqzrfWj7GDDJ3S8CngT+M+Ubmd1tZrVmVtvUFNyZJjfPHk0kZDy6bk9gGURE+ls6hd4AJB9xjwMakzdw9wPu3pFY/AZwaao3cvcH3L3G3Wuqq6vPJm+/GFpSwLXTqnlsbSM9mvRCRHJEOoW+GphqZpPNrAC4A1iRvIGZjU5aXAhs7r+IA2Ph3DE0Hm6ndtehoKOIiPSLPgvd3WPAEuAJ4kX9sLtvNLOlZrYwsdnHzWyjma0DPg7cOVCB+8u7Zo6kOBrm0bUadhGR3GBBnelRU1PjtbW1gfzs4z6xfA3PvtbES39zIwWRvLvGSkSykJm97O41qV7L6xZbNHcMza1dPFenWwGISPbL60K/emo1Q4dEeXRtY98bi4hkuLwu9Gg4xM0XjuYXG/fp3i4ikvXyutABFs0dS1tXN7/ctC/oKCIi5yTvC71m4lBGVxSxQsMuIpLl8r7QQyFj4ZwxPPtaE4eOdQYdR0TkrOV9oUP8IqNYj7Nyw96go4iInDUVOjBzdDnnjyjV2S4iktVU6ICZsWjOGF56/SCNzW1BxxEROSsq9ISFc8cA8Ng6HaWLSHZSoSdMrCph7vhKDbuISNZSoSdZNHcMm/a2sG2fJr4QkeyjQk9yy0WjCRms0LCLiGQhFXqSEWVFzD9/OI+ubdR8oyKSdVTovSycM4bdB1tZW98cdBQRkTOiQu/l3bNHURAJ6cNREck6KvReyoui3DBjBD9dv5dYd0/QcURE0pZWoZvZAjPbamZ1ZnbPaba7zczczFLOppEtFs0dw5tHO/jt9gNBRxERSVufhW5mYWAZcBMwE1hsZjNTbFdGfD7RF/s75GC7bvoIhpUU8F+rdgUdRUQkbekcoc8D6tx9h7t3AsuBRSm2+yfgPqC9H/MFoiga5gOXT+DJzfvYdeBY0HFERNKSTqGPBeqTlhsS604ws4uB8e7+037MFqgPXjGRSMh46PmdQUcREUlLOoVuKdadOEnbzELAl4FP9flGZnebWa2Z1TY1ZfbEzCPLi/jdi8bww9oGjrR3BR1HRKRP6RR6AzA+aXkckHxOXxkwG3jGzHYCVwArUn0w6u4PuHuNu9dUV1effepBctf8yRztiPFwbUPQUURE+pROoa8GpprZZDMrAO4AVhx/0d0Pu/twd5/k7pOAVcBCd68dkMSD6MJxFVw2aSgPPf863T26clREMlufhe7uMWAJ8ASwGXjY3Tea2VIzWzjQAYN21/zJ1B9s48nNmkRaRDJbJJ2N3H0lsLLXus+dYtvrzj1W5njXzJGMrSzmwede592zRgUdR0TklHSlaB8i4RB3XjmJF18/yIY9h4OOIyJySir0NLz3svEMKQjz7d/uDDqKiMgpqdDTUFEc5fZLx/HYukb2H8n666ZEJEep0NN05/zJdHb38L1Vu4OOIiKSkgo9TZOHl3DDjBF878VdtHd1Bx1HROQkKvQzcNdVk3nzaCePaYo6EclAKvQzcOV5VUwfWcaDv92pKepEJOOo0M+AmXHXVZPYvLeFVTsOBh1HRORtVOhnaNHcsQwrKeDB374edBQRkbdRoZ8h3StdRDKVCv0s/GHiXum60EhEMokK/SyMKC/i1jljWL56N/tbdKGRiGQGFfpZ+uQN0+jucb785Lago4iIACr0szahaggfuHwiD9fWU7f/aNBxRERU6OfiY+88n+JomC8+sSXoKCIiKvRzUVVayN3XTOGJjft4edehoOOISJ5ToZ+jP7l6MsNLC/nCzzfr6lERCVRahW5mC8xsq5nVmdk9KV7/iJm9amZrzew5M5vZ/1Ez05CCCJ+8cSqrdx7iV5v3Bx1HRPJYn4VuZmFgGXATMBNYnKKwv+/uF7r7XOA+4Ev9njSDve+y8UwZXsK9j28h1t0TdBwRyVPpHKHPA+rcfYe7dwLLgUXJG7h7S9JiCZBXYw/RcIhPv3s62/Yf5UevNAQdR0TyVDqFPhaoT1puSKx7GzP7CzPbTvwI/eP9Ey97LJg9iosnVPLlX26jrVP3SxeRwZdOoVuKdScdgbv7Mnc/D/hr4O9SvpHZ3WZWa2a1TU1NZ5Y0w5kZ9yyYwRst7Xz7ed24S0QGXzqF3gCMT1oeB5xuhoflwHtSveDuD7h7jbvXVFdXp58yS1w+pYobZozg/me2c+hYZ9BxRCTPpFPoq4GpZjbZzAqAO4AVyRuY2dSkxVuAvL0e/jMLZnCsI8ayp+uCjiIieabPQnf3GLAEeALYDDzs7hvNbKmZLUxstsTMNprZWuAvgQ8NWOIMN31UGX9wyTi+88IuGg61Bh1HRPKIBXUxTE1NjdfW1gbyswdaY3Mb1//bM9xy4Wi+9L65QccRkRxiZi+7e02q13Sl6AAYU1nMnfMn8eO1e9iw53DQcUQkT6jQB8ifX3c+w0sL+cwj6+nSxUYiMghU6AOkojjK/37PbDbtbeH+Z7YHHUdE8oAKfQC9e9Yobp0zhv94ahtb3mjp+xtERM6BCn2A/ePCWZQXRfn0D9frPi8iMqBU6ANsWEkBSxfN5tU9h/n6r3cEHUdEcpgKfRDcctFobpo9iq8+uY1t+44EHUdEcpQKfZAsXTSbksIwn35kPd09eXUzShEZJCr0QVJdVsjnF85ibX0z33pOQy8i0v9U6INo4Zwx3HjBSP79F6+xo+lo0HFEJMeo0AeRmfEvvzebwkiIz2joRUT6mQp9kI0oL+Ifbp1F7a5DPPT8zqDjiEgOUaEH4PcvGcv106v54hNb2PnmsaDjiEiOUKEHwMz4l9+/kGgoxCd/sJb2Lk1ZJyLnToUekNEVxdx320WsrW/mUz9cR4/G00XkHKnQA3TThaP57E0z+Nn6vdz3xNag44hIlosEHSDf3X3NFHYdbOVrz25nwrAhvP/yCUFHEpEsldYRupktMLOtZlZnZvekeP0vzWyTma03s1+Z2cT+j5qbzIylC2dx7bRq/v7RDTyzdX/QkUQkS/VZ6GYWBpYBNwEzgcVmNrPXZmuAGne/CHgEuK+/g+aySDjEsg9cwrSRZSz5/ho2NepWuyJy5tI5Qp8H1Ln7DnfvBJYDi5I3cPen3f34jMirgHH9GzP3lRZG+Padl1FaGOGuh1bzxuH2oCOJSJZJp9DHAvVJyw2JdafyYeDn5xIqX42qKOLBOy/jSHsXdz20mqMdsaAjiUgWSafQLcW6lOfYmdkHgRrgi6d4/W4zqzWz2qampvRT5pGZY8pZ9oFL2LrvCEu+/4omxRCRtKVT6A3A+KTlcUBj743M7Ebgb4GF7t6R6o3c/QF3r3H3murq6rPJmxeumz6Cf1o0m2e2NvEPKzbirnPURaRv6Zy2uBqYamaTgT3AHcD7kzcws4uBrwML3F2nafSD918+gd2J0xmj4RCf+92ZhEKp/lgSEYnrs9DdPWZmS4AngDDwoLtvNLOlQK27ryA+xFIK/NDMAHa7+8IBzJ0XPvPu6XR19/Ct517nUGsnX7xtDgURXQsmIqmldWGRu68EVvZa97mk5zf2cy4BQiHj7265gOGlhdz7+BaaW7u4/4OXMKRA14OJyMl0uJfhzIyPXnce9/7BhfxmWxPv/8aLHDrWGXQsEclAKvQs8b7LJnD/By9l094Wbv/6CzQ2twUdSUQyjAo9i7x71ii+c9c89h1u57b7n6duv6axE5G3qNCzzBVTqlj+Z1fQ2e3c/rXnWVvfHHQkEckQKvQsNGtMBT/66DsoLYrw/m+s4uktOlNURFToWWtiVQk/+siVTKwq4Y8fWs29j2+hS1eViuQ1FXoWG1FexP989EoWz5vA/c9s531ff4GGQ619f6OI5CQVepYrLgjzr79/If+x+GK27TvKzV/9DY9v2Bt0LBEJgAo9R9w6Zww/+/jVTB5ewkf+6xX+/icbNPm0SJ5RoeeQCVVD+OFHruRPr57Md1ft4j3LfqtTG0XyiAo9xxREQvztLTP59p2Xsf9IB7f+x3P8sLZed2wUyQMq9Bx1/YwRrPz41cwZX8GnH1nPH37rJR2ti+Q4FXoOG1VRxPf+5AqWLprF+oZmbvrqr/nCz7dwTDMhieQkFXqOC4eMP3rHJJ76q+t4z9yxfO3Z7dz4pWf52fq9GoYRyTEq9DwxvLSQL94+hx999B0MHVLAX3z/FQ3DiOQYFXqeuXTiMFYsmc8/LpzFOg3DiOQUFXoeioRDfOjKSTz1qetYlBiGufq+p/l/z9RxVMUukrXSKnQzW2BmW82szszuSfH6NWb2ipnFzOy2/o8pA6G6rJB/u30OP/7zK7lwbAX3Pb6Vq+59imVP13GkvSvoeCJyhqyvD8bMLAy8BrwLaCA+afRid9+UtM0koBz4K2CFuz/S1w+uqanx2trasw4u/W/N7kP8n19t4+mtTVQUR/nwVZO5c/4kyouiQUcTkQQze9nda1K9ls4R+jygzt13uHsnsBxYlLyBu+909/WAbveXxS6eMJRv//E8ViyZz2WThvKlX77GVV94iq88+RqH23TELpLp0in0sUB90nJDYp3kqIvGVfLND13GTz92FVdMqeIrT25j/hee4u9/soGtbxwJOp6InEI608dbinVndQKzmd0N3A0wYcKEs3kLGUSzx1bwwB/VsLHxMN967nV+UFvPd1ftYt6kYXzgigksmD2Kwkg46JgikpDOEXoDMD5peRzQeDY/zN0fcPcad6+prq4+m7eQAMwaU8GX3juXFz97A39z8wz2HWnnE8vXcuW/PsV9j2+h/qDuwS6SCdL5UDRC/EPRG4A9xD8Ufb+7b0yx7UPAT/WhaG7r6XF+U/cm/7VqF7/avA8Hrp8+gtsvHcf1M0ZQFNVRu8hAOd2Hon0WeuINbga+AoSBB939n81sKVDr7ivM7DLgx8BQoB14w91nne49Vei5obG5jeUv7ea/V9fTdKSD0sIIvzNzJLfOGcNVU4cTDetSB5H+dM6FPhBU6Lkl1t3Dqh0HeWxdIz/fsJeW9hiVQ6LcNHs0t84ZzeWTqwiHUn0cIyJnQoUug6oz1sOvX2visfWN/HLTPlo7uxlRVshNs0fxzgtGcvnkYRqWETlLKnQJTFtnN09t2c+KdXt4ZmsTHbEeiqNh5p8/nOtnVHP99BGMqSwOOqZI1jhdoadz2qLIWSsuCHPLRaO55aLRtHd188L2Azy9dT9PbdnPk5v3ATBjVBnXzxjBO2eMYO74So27i5wlHaFLINyduv1HeWrLfp7eup/anYeI9ThDCsJcOnEoV0yp4oopw7hwbCUFERW8yHEacpGM19LexXPb3mTVjgO8uOMgW/fFr0gtioa4dOJQLp9cxRVTqpgzvkIXM0leU6FL1jl4rJOXXj/Aqh0HWbXjAFsStxwoCIe4YEw5c8dVMGd8JXPHVzKpqoSQzqCRPKFCl6x36FgnL+08yCu7DrG2vplX9xymtbMbgPKiyIlynzOukpljyhldUYSZSl5yjwpdck53T3wMfl19M2vqm1lX38zWfUfo7on//1xRHGXGqDIuGF3OBaPjj9NGlul0Scl6OstFck44ZEwfVcb0UWW897L4rYbaOrvZtPcwm/YeYfPeFrbsbeHh2voTR/Ihg8nDS5gxqpzzqks4b0Qp51WXMqW6hCEF+qcg2U//F0vOKC4Ic+nEYVw6cdiJdT09zu6DrWx5o+VE0W/a28LPN+ylJ+mP07GVxUypLuG86lLOqy5hYlUJE6uGMLaymIhOo5QsoUKXnBYKGZOGlzBpeAkLZo8+sb4j1s2uA61s33+U7U1H2d50jLr9R992RA/xvwTGVhYzsWoIE4YNSTyWMH5YMWMri6kojmqsXjKGCl3yUmEkzLSRZUwbWfa29e7OGy3t7DrQyu4Drew6eIzdB9vYfeAYP3t1L82tb5+5qaQgzJjK4hNf44YWM6ayiNEVxYwqL2JkeRHFBRq3l8GhQhdJYmaMrihmdEUxV0ypOun1w21d7D7QSsOhVvY0t7GnuY3G5jYam9t5dc9hDh7rPOl7yosijEyU+4jywvjzskKGlxUyrKSAqpJCqkoLGDqkQDcwk3OiQhc5AxXFUS4cV8GF4ypSvt7W2U3j4XjJ72vpYF9LO/tb2uPPj7Tz4o5j7D/STlf3yWeXmUFlcZSq0uNFX0BFcZSKIdH4Y3GUyuL4usrEuvLiKGWFEZ2HL4AKXaRfFReEEx+slp5ym54e51BrJweOdfLm0Q4OHuvkwNH48sFjHSeeb9t/lMNtXRxu66Izdur510MGZUVvlX686CMnCr+iOEp5UfLzyNvW69YKuUOFLjLIQiGjqrSQqtLCk8bwU3F32rt6TpR7c2tn/LGti5bEut5fjYfbTryW6q+BZIWREGVFEUoLI5QWRSgrjCYe48ulhRFKCiOUFIQpKYwvDymMUFoYTqyPMKQgzJCCCEXRkD4kDpAKXSTDmRnFBWGKC8KMqig6o+91dzpi8V8GLW1dtLR30dIWo6W968S6Ix0xjrTHONoe42hHjCPtXdQfbOVox/Hl2IkLtvrOCkOiYYpPlHw4qezj/w1DEo9F0TDF0TDFBSGKo2EKo/F1RZHQiW2LImGKovHlwmiIwkiYwkiIwoh+caSiQhfJYWYWL8lomJHlZ/bL4LjjvxSOdcRo7ezmaEeM1s4YRzu6OZYo/bbOblo7u2ntjCUek5/Htz9wrJP2rm7aOrtpSzx2dp96KKkvx4u9MPpWyRckCr/g+GuR+C+BgkiIgnB8/fGvaDjxPeEQ0bBREAknHo+vCxGNJF47vpzYNhoOEUmsjyQ/DxnhkAX2yyatQjezBcBXic8p+k13/0Kv1wuB7wCXAgeA97n7zv6NKiJBSP6lcPJ5P+cm1t1De6yH1s4YHV09tHd1097VQ3us+63nXfHnHbGeE4/xr246uhLPe63vjPVwpD3GgePL3T10dPXQ1d1DZ6yHzu6ePoeizpYZREJGJBQv+mii6I//EoiEjE/cOI2Fc8b0+8/us9DNLAwsA94FNACrzWyFu29K2uzDwCF3P9/M7gDuBd7X72lFJKdEwiFKwyFKCwd/sMDdTxR7Z6znxFdXT7z4u2LHX3/rqzMW3z7WE3+9q6eHrlgPsZ74trFup6s7vhzrfmvb+Pq3ng8dEh2Q/6Z09uI8oM7ddwCY2XJgEZBc6IuAzyeePwL8XzMzD+rOXyIifTCzxJg8UBh0mv6RzvlKY4H6pOWGxLqU27h7DDgMJ/91ZmZ3m1mtmdU2NTWdXWIREUkpnUJPNbrf+8g7nW1w9wfcvcbda6qrq9PJJyIiaUqn0BuA8UnL44DGU21jZhGgAjjYHwFFRCQ96RT6amCqmU02swLgDmBFr21WAB9KPL8NeErj5yIig6vPD0XdPWZmS4AniJ+2+KC7bzSzpUCtu68AvgV818zqiB+Z3zGQoUVE5GRpnSvk7iuBlb3WfS7peTtwe/9GExGRM6G78oiI5AgVuohIjrCgPrs0syZg11l++3DgzX6MM5CyJaty9q9syQnZk1U54ya6e8rzvgMr9HNhZrXuXhN0jnRkS1bl7F/ZkhOyJ6ty9k1DLiIiOUKFLiKSI7K10B8IOsAZyJasytm/siUnZE9W5exDVo6hi4jIybL1CF1ERHrJukI3swVmttXM6szsnqDznIqZ7TSzV81srZnVBp0nmZk9aGb7zWxD0rphZvZLM9uWeBwaZMZEplQ5P29mexL7da2Z3RxkxkSm8Wb2tJltNrONZvaJxPqM2qenyZlR+9TMiszsJTNbl8j5j4n1k83sxcT+/EHi3lKBOk3Wh8zs9aR9OndQArl71nwRv5fMdmAKUACsA2YGnesUWXcCw4POcYps1wCXABuS1t0H3JN4fg9wb4bm/DzwV0Fn65VzNHBJ4nkZ8BowM9P26WlyZtQ+JX477tLE8yjwInAF8DBwR2L914CPZnDWh4DbBjtPtmnThz4AAAKdSURBVB2hn5g9yd07geOzJ8kZcPdfc/LtjRcB/5l4/p/AewY1VAqnyJlx3H2vu7+SeH4E2Ex80peM2qenyZlRPO5oYjGa+HLgncRnRIMM2J9w2qyByLZCT2f2pEzhwC/M7GUzuzvoMGkY6e57If4PHxgRcJ7TWWJm6xNDMoEPDSUzs0nAxcSP1DJ2n/bKCRm2T80sbGZrgf3AL4n/Zd7s8RnRIIP+7ffO6u7H9+k/J/bpl81sUCa5y7ZCT2tmpAwx390vAW4C/sLMrgk6UI64HzgPmAvsBf492DhvMbNS4EfAJ929Jeg8p5IiZ8btU3fvdve5xCfUmQdckGqzwU2VWu+sZjYb+CwwA7gMGAb89WBkybZCT2f2pIzg7o2Jx/3Aj4n/T5nJ9pnZaIDE4/6A86Tk7vsS/4B6gG+QIfvVzKLES/J77v4/idUZt09T5czUfQrg7s3AM8THpSsTM6JBBv7bT8q6IDG85e7eAXybQdqn2Vbo6cyeFDgzKzGzsuPPgd8BNpz+uwKXPOvUh4BHA8xySscLMuH3yID9amZGfJKXze7+paSXMmqfnipnpu1TM6s2s8rE82LgRuLj/U8TnxENMmB/wimzbkn6RW7Ex/oHZZ9m3YVFiVOqvsJbsyf9c8CRTmJmU4gflUN8EpHvZ1JOM/tv4Drid4XbB/wD8BPiZxFMAHYDt7t7oB9IniLndcSHBpz4mUR/dnycOihmdhXwG+BVoCex+m+Ij09nzD49Tc7FZNA+NbOLiH/oGSZ+0Pmwuy9N/LtaTnwIYw3wwcQRcGBOk/UpoJr4MPFa4CNJH54OXJ5sK3QREUkt24ZcRETkFFToIiI5QoUuIpIjVOgiIjlChS4ikiNU6CIiOUKFLiKSI1ToIiI54v8D7x4mD4YRIhUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(error_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards_grid = rewards.reshape((g.length_max, g.height, g.width))\n",
    "rewards_grid = rewards_grid[0,:,:]\n",
    "\n",
    "# Map\n",
    "\n",
    "plt.imshow(rewards_grid);\n",
    "plt.title('Rewards')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.35855875, -1.35637205, -1.35418534,  0.15856006],\n",
       "        [-1.02567137,  0.33507408,  0.41326076,  0.49144743],\n",
       "        [-0.692784  ,  0.74396143,  0.74614813,  0.82433481]],\n",
       "\n",
       "       [[-1.36308677, -1.36090006, -1.35871336,  0.15403204],\n",
       "        [-1.03019939,  0.33054606,  0.40873274,  0.48691941],\n",
       "        [-0.69731202,  0.73943341,  0.74162011,  0.81980679]],\n",
       "\n",
       "       [[-1.36761478, -1.36542808, -1.36324138,  0.14950402],\n",
       "        [-1.03472741,  0.32601805,  0.40420472,  0.4823914 ],\n",
       "        [-0.70184003,  0.73490539,  0.7370921 ,  0.81527877]],\n",
       "\n",
       "       [[-1.3721428 , -1.3699561 , -1.36776939,  0.144976  ],\n",
       "        [-1.03925543,  0.32149003,  0.3996767 ,  0.47786338],\n",
       "        [-0.70636805,  0.73037738,  0.73256408,  0.81075076]],\n",
       "\n",
       "       [[-1.37667082, -1.37448411, -1.37229741,  0.14044799],\n",
       "        [-1.04378344,  0.31696201,  0.39514869,  0.47333536],\n",
       "        [-0.71089607,  0.72584936,  0.72803606,  0.80622274]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards.reshape((g.length_max, g.height, g.width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_demonstrations(g, policy, n_trajs=10, len_traj=5):\n",
    "    \"\"\"gatheres expert demonstrations\n",
    "    inputs:\n",
    "    policy      Nx1 matrix\n",
    "    n_trajs     int - number of trajectories to generate\n",
    "    rand_start  bool - randomly picking start position or not\n",
    "    start_pos   2x1 list - set start position, default [0,0]\n",
    "    returns:\n",
    "    trajs       a list of trajectories - each element in the list is a list of Steps representing an episode\n",
    "    \"\"\"\n",
    "\n",
    "    trajs = []\n",
    "    for i in range(n_trajs):\n",
    "        \n",
    "        episode = []\n",
    "        state = (0,1,1)\n",
    "        idx = g.state2idx(state)\n",
    "        episode.append(idx)\n",
    "        \n",
    "        # while not is_done:\n",
    "        for _ in range(len_traj-1):\n",
    "\n",
    "            act = np.random.choice(g.n_actions, p= policy[idx,:])\n",
    "            next_state = g.get_next_state(state, act)\n",
    "            next_idx = g.state2idx(next_state)\n",
    "            episode.append(next_idx)\n",
    "            state = next_state\n",
    "            idx = next_idx\n",
    "            \n",
    "        trajs.append(episode)\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 17, 29, 42, 53],\n",
       " [5, 21, 34, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 18, 34, 46, 53],\n",
       " [5, 22, 35, 46, 53],\n",
       " [5, 17, 34, 46, 53],\n",
       " [5, 18, 29, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 21, 33, 41, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 22, 33, 45, 53],\n",
       " [5, 22, 35, 42, 53],\n",
       " [5, 21, 33, 46, 53],\n",
       " [5, 18, 30, 45, 53],\n",
       " [5, 18, 34, 46, 53],\n",
       " [5, 21, 34, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 21, 29, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 22, 33, 45, 53],\n",
       " [5, 22, 31, 46, 53],\n",
       " [5, 17, 34, 41, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 21, 33, 46, 53],\n",
       " [5, 21, 30, 45, 53],\n",
       " [5, 21, 30, 46, 53],\n",
       " [5, 22, 31, 46, 53],\n",
       " [5, 21, 33, 45, 53],\n",
       " [5, 21, 33, 45, 53],\n",
       " [5, 22, 34, 45, 53],\n",
       " [5, 18, 35, 46, 53],\n",
       " [5, 18, 27, 42, 53],\n",
       " [5, 21, 33, 42, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 18, 31, 42, 53],\n",
       " [5, 17, 33, 45, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 16, 33, 45, 53],\n",
       " [5, 18, 35, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 18, 35, 46, 53],\n",
       " [5, 22, 30, 46, 53],\n",
       " [5, 17, 30, 46, 53],\n",
       " [5, 18, 35, 46, 53],\n",
       " [5, 21, 33, 45, 53],\n",
       " [5, 18, 35, 46, 53],\n",
       " [5, 21, 33, 45, 53]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajs = generate_demonstrations(g, policy, 50, 5)\n",
    "trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   1.],\n",
       "       [  1., 110.,  21.,   3.],\n",
       "       [  0.,  36.,  71.,   7.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = np.zeros((3,4))\n",
    "for traj in trajs:\n",
    "    for idx in traj:\n",
    "        state = g.idx2state(idx)\n",
    "        freq[state[1], state[2]] += 1\n",
    "        \n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep\n",
    "\n",
    "Deep MaxEnt Inverse reinforcement Learning - the reward function is a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_map = torch.tensor([[map_mask, map_dist, map_gradv, map_gradh, map_const]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 3, 4])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_map.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input tensor must be of size $(N,C_{in},H,W)$ \n",
    "\n",
    "with \n",
    "- $N$ batch size\n",
    "- $C_{in}$ number of channels\n",
    "- $H$ height of the image\n",
    "- $W$ width of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.length_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = nn.Sequential(\n",
    "            nn.Conv2d(5, 5, kernel_size = 3, stride=1, padding=1))\n",
    "\n",
    "layer2 = nn.Sequential(\n",
    "            nn.Conv2d(5, 5, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 3, 4])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2(layer1(x)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(5, 5, kernel_size = 3, stride=1, padding=1))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(5, 5, kernel_size = 3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        return out\n",
    "    \n",
    "    def get_reward_mat(self, x):\n",
    "        out = self.forward(x)\n",
    "        rewards = out.detach().numpy()\n",
    "        return -rewards[0].reshape((60,1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.73765802e-01],\n",
       "       [-3.73256505e-01],\n",
       "       [-2.60760218e-01],\n",
       "       [-1.43410683e-01],\n",
       "       [-4.21943843e-01],\n",
       "       [-3.82943034e-01],\n",
       "       [-1.02125406e-01],\n",
       "       [-1.30047098e-01],\n",
       "       [-0.00000000e+00],\n",
       "       [-6.01871386e-02],\n",
       "       [-0.00000000e+00],\n",
       "       [-4.66974303e-02],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-1.40328854e-01],\n",
       "       [-1.05537176e-02],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-1.78463280e-01],\n",
       "       [-8.74055475e-02],\n",
       "       [-9.39313546e-02],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-6.07213490e-02],\n",
       "       [-1.25839174e-01],\n",
       "       [-3.45807080e-03],\n",
       "       [-0.00000000e+00],\n",
       "       [-3.72879095e-02],\n",
       "       [-0.00000000e+00],\n",
       "       [-6.28970191e-02],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-2.24352390e-01],\n",
       "       [-0.00000000e+00],\n",
       "       [-6.51343465e-02],\n",
       "       [-0.00000000e+00],\n",
       "       [-2.52491347e-02],\n",
       "       [-0.00000000e+00],\n",
       "       [-2.09703241e-04],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-1.70105666e-01],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00],\n",
       "       [-0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "model.get_reward_mat(feat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_svf(trajs, n_states):\n",
    "    \"\"\"\n",
    "    compute state visitation frequences from demonstrations\n",
    "\n",
    "    input:\n",
    "    trajs   list of list of Steps - collected from expert\n",
    "    returns:\n",
    "    p       Nx1 vector - state visitation frequences   \n",
    "    \"\"\"\n",
    "\n",
    "    p = np.zeros(n_states)\n",
    "    for traj in trajs:\n",
    "        for step in traj:\n",
    "            p[step] += 1\n",
    "    p = p/len(trajs)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "mu_D = demo_svf(trajs, P.shape[0])\n",
    "\n",
    "# Run the forward pass\n",
    "rewards = model.get_reward_mat(feat_map)\n",
    "\n",
    "# compute policy \n",
    "_, policy = value_iteration(P, rewards, error=0.01, max_iter=100)\n",
    "\n",
    "# compute expected svf\n",
    "mu_exp = compute_state_visition_freq(P, g.state2idx((0,1,1)), g.length_max, policy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute gradients on rewards:\n",
    "grad_r = mu_D - mu_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  2.8655e-02,  1.6064e-02, -8.2500e-02,\n",
       "         0.0000e+00,  2.9507e-02,  4.9306e-02, -4.2688e-02,  0.0000e+00,\n",
       "        -1.1153e-01,  5.5877e-02,  5.7312e-02,  0.0000e+00, -1.2794e-01,\n",
       "        -1.2783e-01, -2.0774e-02, -1.8230e-02, -1.1955e-01,  3.0555e-01,\n",
       "         3.1480e-02, -7.0184e-03, -1.2823e-01,  2.1183e-01, -7.7016e-04,\n",
       "         1.4822e-03, -6.0445e-02, -2.1109e-02, -1.0999e-02,  0.0000e+00,\n",
       "        -7.4506e-02,  2.5242e-02,  4.2648e-02,  0.0000e+00, -9.1032e-02,\n",
       "         1.4115e-01,  4.9052e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.2204e-16,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(grad_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.89303905e-01]\n",
      " [-5.14828682e-01]\n",
      " [-3.11649352e-01]\n",
      " [-1.57838061e-01]\n",
      " [-2.55378038e-01]\n",
      " [-6.26967669e-01]\n",
      " [-4.08533275e-01]\n",
      " [-1.41879320e-01]\n",
      " [-6.50388300e-02]\n",
      " [-1.74619257e-01]\n",
      " [-5.99824823e-02]\n",
      " [-1.96984205e-02]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-8.16344917e-02]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-4.19364456e-04]\n",
      " [-8.05720627e-01]\n",
      " [-2.34009549e-01]\n",
      " [-4.60737914e-01]\n",
      " [-2.31414214e-01]\n",
      " [-5.54287434e-01]\n",
      " [-2.03869998e-01]\n",
      " [-2.68962681e-01]\n",
      " [-1.32846013e-01]\n",
      " [-3.42594743e-01]\n",
      " [-2.40729041e-02]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-5.82783163e-01]\n",
      " [-2.34720826e-01]\n",
      " [-1.85661241e-01]\n",
      " [-1.09472334e-01]\n",
      " [-1.41268283e-01]\n",
      " [-0.00000000e+00]\n",
      " [-8.38323776e-03]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-1.70762893e-02]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-1.36651024e-01]\n",
      " [-1.80352718e-01]\n",
      " [-1.47113234e-01]\n",
      " [-1.66999206e-01]\n",
      " [-0.00000000e+00]\n",
      " [-0.00000000e+00]\n",
      " [-2.47200783e-02]\n",
      " [-1.70025542e-01]]\n"
     ]
    }
   ],
   "source": [
    "# apply gradients to the neural network\n",
    "opt.zero_grad()\n",
    "torch.autograd.backward([model(feat_map)], [torch.tensor(grad_r.reshape((1,5,3,4)))]) \n",
    "opt.step()\n",
    "rewards = model.get_reward_mat(feat_map)\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_maxent_irl(feat_map, P_a, trajs, lr, n_iters):\n",
    "    \"\"\"\n",
    "    Maximum Entropy Inverse Reinforcement Learning (Maxent IRL)\n",
    "    inputs:\n",
    "    feat_map    NxD matrix - the features for each state\n",
    "    P_a         NxNxN_ACTIONS matrix - P_a[s0, s1, a] is the transition prob of \n",
    "                                   landing at state s1 when taking action \n",
    "                                   a at state s0\n",
    "    gamma       float - RL discount factor\n",
    "    trajs       a list of demonstrations\n",
    "    lr          float - learning rate\n",
    "    n_iters     int - number of optimization steps\n",
    "    returns\n",
    "    rewards     Nx1 vector - recoverred state rewards\n",
    "    \"\"\"\n",
    "\n",
    "    # tf.set_random_seed(1)\n",
    "\n",
    "    N_STATES, _, N_ACTIONS = np.shape(P_a)\n",
    "\n",
    "    # init nn model\n",
    "    model = ConvNet()\n",
    "    mu_D = demo_svf(trajs, P.shape[0])\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "    \n",
    "\n",
    "    error_history = []\n",
    "    \n",
    "    # training \n",
    "    for iteration in range(n_iters):\n",
    "        if iteration % (n_iters/10) == 0:\n",
    "            print('iteration: {}'.format(iteration))\n",
    "\n",
    "        # compute the reward matrix\n",
    "        rewards = model.get_reward_mat(feat_map)\n",
    "\n",
    "        # compute policy \n",
    "        _, policy = value_iteration(P_a, rewards, error=0.01, max_iter=100)\n",
    "\n",
    "        # compute expected svf\n",
    "        mu_exp = compute_state_visition_freq(P_a, g.state2idx((0,1,1)), g.length_max, policy)\n",
    "\n",
    "        # compute gradients on rewards:\n",
    "        grad_r = mu_D - mu_exp\n",
    "\n",
    "        error_history.append(sum(grad_r**2)) \n",
    "        \n",
    "        plt.plot(error_history)\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        IPython.display.display(plt.show())\n",
    "\n",
    "            \n",
    "        # apply gradients to the neural network\n",
    "        opt.zero_grad()\n",
    "        torch.autograd.backward([model(feat_map)], [torch.tensor(grad_r.reshape((1,5,3,4)))]) \n",
    "        opt.step()\n",
    "\n",
    "\n",
    "    rewards = model.get_reward_mat(feat_map)\n",
    "        \n",
    "    return rewards, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards,policy = deep_maxent_irl(feat_map, P, trajs, 0.1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.07499631, -0.1967707 , -0.66800904, -0.11738005],\n",
       "       [-0.        , -0.        , -0.48121646, -0.4125611 ],\n",
       "       [-0.        , -0.        , -0.07293803, -0.24021767]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards_grid = rewards.reshape((g.length_max, g.height, g.width))\n",
    "rewards_grid = rewards_grid[0,:,:]\n",
    "\n",
    "# Map\n",
    "\n",
    "plt.imshow(rewards_grid);\n",
    "plt.title('Rewards')\n",
    "plt.show()\n",
    "\n",
    "rewards_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 21, 33, 45, 53],\n",
       " [5, 14, 30, 37, 53],\n",
       " [5, 17, 33, 46, 53],\n",
       " [5, 17, 34, 46, 53],\n",
       " [5, 21, 33, 42, 53],\n",
       " [5, 18, 27, 42, 53],\n",
       " [5, 13, 25, 37, 53],\n",
       " [5, 18, 30, 37, 53],\n",
       " [5, 21, 30, 46, 53],\n",
       " [5, 17, 33, 45, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 18, 33, 46, 53],\n",
       " [5, 16, 33, 40, 53],\n",
       " [5, 14, 27, 42, 53],\n",
       " [5, 14, 29, 41, 53],\n",
       " [5, 20, 33, 44, 53],\n",
       " [5, 14, 31, 46, 53],\n",
       " [5, 16, 33, 40, 53],\n",
       " [5, 18, 35, 42, 53],\n",
       " [5, 20, 29, 40, 53],\n",
       " [5, 20, 32, 44, 53],\n",
       " [5, 21, 30, 45, 53],\n",
       " [5, 14, 26, 38, 53],\n",
       " [5, 17, 30, 38, 53],\n",
       " [5, 18, 26, 38, 53],\n",
       " [5, 13, 25, 37, 53],\n",
       " [5, 14, 30, 46, 53],\n",
       " [5, 21, 34, 46, 53],\n",
       " [5, 14, 26, 38, 53],\n",
       " [5, 14, 26, 42, 53],\n",
       " [5, 14, 26, 41, 53],\n",
       " [5, 20, 33, 46, 53],\n",
       " [5, 16, 25, 40, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 18, 34, 41, 53],\n",
       " [5, 18, 33, 42, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 18, 26, 38, 53],\n",
       " [5, 18, 29, 38, 53],\n",
       " [5, 17, 34, 45, 53],\n",
       " [5, 12, 25, 40, 53],\n",
       " [5, 20, 33, 45, 53],\n",
       " [5, 14, 26, 38, 53],\n",
       " [5, 21, 33, 45, 53],\n",
       " [5, 21, 33, 41, 53],\n",
       " [5, 18, 31, 46, 53],\n",
       " [5, 21, 33, 45, 53],\n",
       " [5, 21, 29, 42, 53],\n",
       " [5, 18, 34, 42, 53]]"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajs = generate_demonstrations(g, policy, 50, 5)\n",
    "trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,  10.,  24.,   2.],\n",
       "       [  8., 113.,  25.,   2.],\n",
       "       [  8.,  30.,  26.,   1.]])"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = np.zeros((3,4))\n",
    "for traj in trajs:\n",
    "    for idx in traj:\n",
    "        state = g.idx2state(idx)\n",
    "        freq[state[1], state[2]] += 1\n",
    "        \n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

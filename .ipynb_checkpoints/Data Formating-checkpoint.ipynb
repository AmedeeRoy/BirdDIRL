{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data\n",
    "\n",
    "Seabird Data Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/home/amdroy/MEGA/DATA/seabirdbank.db')\n",
    "\n",
    "request = \"SELECT DISTINCT  bird.id as bird, trip.id as trip, gps.datetime, gps.lon, gps.lat FROM gps \\\n",
    "INNER JOIN trip ON gps.trip = trip.id \\\n",
    "INNER JOIN bird ON trip.bird = bird.id \\\n",
    "WHERE bird.fieldwork = 'P1108' \\\n",
    "AND bird.species = 'SV' \\\n",
    "AND bird.sex = 'M'\"\n",
    "\n",
    "df = pd.read_sql_query(request, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bird</th>\n",
       "      <th>trip</th>\n",
       "      <th>datetime</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>P1108_2_SV_T1</td>\n",
       "      <td>P1108_2_SV</td>\n",
       "      <td>P1108_2_SV_T1</td>\n",
       "      <td>2008-11-24 16:38:11</td>\n",
       "      <td>-77.264312</td>\n",
       "      <td>-11.773676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>P1108_2_SV_T1</td>\n",
       "      <td>P1108_2_SV</td>\n",
       "      <td>P1108_2_SV_T1</td>\n",
       "      <td>2008-11-24 16:38:13</td>\n",
       "      <td>-77.264359</td>\n",
       "      <td>-11.773425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>P1108_2_SV_T1</td>\n",
       "      <td>P1108_2_SV</td>\n",
       "      <td>P1108_2_SV_T1</td>\n",
       "      <td>2008-11-24 16:38:15</td>\n",
       "      <td>-77.264492</td>\n",
       "      <td>-11.773189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>P1108_2_SV_T1</td>\n",
       "      <td>P1108_2_SV</td>\n",
       "      <td>P1108_2_SV_T1</td>\n",
       "      <td>2008-11-24 16:38:17</td>\n",
       "      <td>-77.264692</td>\n",
       "      <td>-11.773028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>P1108_2_SV_T1</td>\n",
       "      <td>P1108_2_SV</td>\n",
       "      <td>P1108_2_SV_T1</td>\n",
       "      <td>2008-11-24 16:38:19</td>\n",
       "      <td>-77.264919</td>\n",
       "      <td>-11.772915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bird           trip             datetime        lon  \\\n",
       "trip                                                                       \n",
       "P1108_2_SV_T1  P1108_2_SV  P1108_2_SV_T1  2008-11-24 16:38:11 -77.264312   \n",
       "P1108_2_SV_T1  P1108_2_SV  P1108_2_SV_T1  2008-11-24 16:38:13 -77.264359   \n",
       "P1108_2_SV_T1  P1108_2_SV  P1108_2_SV_T1  2008-11-24 16:38:15 -77.264492   \n",
       "P1108_2_SV_T1  P1108_2_SV  P1108_2_SV_T1  2008-11-24 16:38:17 -77.264692   \n",
       "P1108_2_SV_T1  P1108_2_SV  P1108_2_SV_T1  2008-11-24 16:38:19 -77.264919   \n",
       "\n",
       "                     lat  \n",
       "trip                      \n",
       "P1108_2_SV_T1 -11.773676  \n",
       "P1108_2_SV_T1 -11.773425  \n",
       "P1108_2_SV_T1 -11.773189  \n",
       "P1108_2_SV_T1 -11.773028  \n",
       "P1108_2_SV_T1 -11.772915  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.set_index(\"trip\", drop = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid():\n",
    "    def __init__(self, lon, lat):\n",
    "        self.lon = lon\n",
    "        self.lat = lat[::-1]\n",
    "        \n",
    "        self.size = (len(lat), len(lon))\n",
    "        \n",
    "        self.grid = np.array([[(lon, lat) for lon in self.lon] for lat in self.lat])\n",
    "        self.grid_lon = np.array([[lon for lon in self.lon] for lat in self.lat])\n",
    "        self.grid_lat = np.array([[lat for lon in self.lon] for lat in self.lat])\n",
    "        \n",
    "        self.feature = {}\n",
    "        \n",
    "        self.trajs = {}\n",
    "        \n",
    "    # UTILS ----------------------------------------     \n",
    "    def coord2idx(self, coord):\n",
    "        return (np.argmin(abs(self.lat - coord[1])), np.argmin(abs(self.lon - coord[0])))\n",
    "        \n",
    "    def idx2coord(self, idx):\n",
    "        return self.grid[idx]\n",
    "\n",
    "     # ADDING TRAJECTORY ----------------------------------------   \n",
    "    def add_trajectory(self, time, traj, name):\n",
    "        # get position on grid\n",
    "        state = [(np.argmin(abs(self.lat - traj[i,1])), np.argmin(abs(self.lon - traj[i,0]))) \n",
    "                 for i in range(traj.shape[0])]\n",
    "        \n",
    "        # group identical consecutive states\n",
    "        grouped_state = [(k, sum(1 for i in j)) for k,j in groupby(state)]\n",
    "        indexes = [s[1] for s in grouped_state]\n",
    "        step_length = np.zeros(len(indexes))\n",
    "\n",
    "        # test if there is gaps in data\n",
    "        step_start = 0\n",
    "        step_end = indexes[0]\n",
    "        for i in range(len(indexes)-1):\n",
    "            step_length[i] = seconds_between( time[step_start], time[step_end])\n",
    "            step_start = np.sum(indexes[0:i+1])\n",
    "            step_end = np.sum(indexes[0:i+2])\n",
    "\n",
    "        # create trajectory\n",
    "        traj_new = [grouped_state[i][0] for i in range(len(grouped_state)) for j in range(int(np.round(step_length[i]/60)))]\n",
    "        self.trajs[name] = traj_new\n",
    "    \n",
    "    def show_trajectory(self, name):\n",
    "        grid = 0*self.grid_lon\n",
    "        for step in self.trajs[name]:\n",
    "            grid[step[0], step[1]] += 1\n",
    "        return grid\n",
    "        \n",
    "    # ADDING FEATURE MAPS ----------------------------------------\n",
    "    def format_feature(self, x, y, data):\n",
    "        feature = np.zeros(self.size)\n",
    "\n",
    "        xx = np.array([[self.lat[np.argmin(abs(self.lat - i))] for j in y] for i in x])\n",
    "        yy = np.array([[self.lon[np.argmin(abs(self.lon - j))] for j in y] for i in x])\n",
    "\n",
    "        for i in range(len(self.lat)):\n",
    "            for j in range(len(self.lon)):\n",
    "                feature[i,j] = np.mean(data[(yy == self.lon[j]) * (xx == self.lat[i])])\n",
    "                \n",
    "        return feature\n",
    "        \n",
    "    def add_feature(self, x, y, data, name):\n",
    "        self.feature[name] = self.format_feature(x,y,data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Grid(np.arange(-77.8, -77, 0.03), np.arange(-12.1, -11.4, 0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARYAAAD4CAYAAAApdMkJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAKrklEQVR4nO3cUYild3nH8e+vyWaF1cIGTVhjWm0M0lDoKkMqpJSUEI3ebLywdS/KFoRVMKDSiwZvzI0QStXeFMtKFregUamm2YtQTYOQFqpkEoLZuLXZhlXXXXYbUjDerJvk6cW8C9PJzM7knOfMOe/k+4HlnPPOO/M++7Lz5X3P/GdTVUhSp9+a9wCSdh7DIqmdYZHUzrBIamdYJLW7ejsPdk1215vYs52HlDRDL/G/L1TV29Zu39awvIk9/FHu2M5DSpqhf61/+tl626e6FUpyV5KfJjmV5N5pvpaknWPisCS5Cvh74EPALcDBJLd0DSZpvKa5YrkVOFVVz1fVb4BvAgd6xpI0ZtOE5QbgF6tenxm2/T9JDidZTrJ8iYtTHE7SWEwTlqyz7TW/eFRVR6pqqaqWdrF7isNJGotpwnIGuHHV63cAZ6cbR9JOME1YngBuTvKuJNcAHwOO94wlacwmXsdSVS8nuQf4HnAVcLSqnm2bTNJoTbVArqoeAR5pmkXSDuHvCklqZ1gktTMsktoZFkntDIukdoZFUjvDIqmdYZHUzrBIamdYJLUzLJLaGRZJ7QyLpHaGRVI7wyKpnWGR1M6wSGpnWCS1MyyS2hkWSe0Mi6R2hkVSO8MiqZ1hkdTOsEhqZ1gktTMsktoZFkntDIukdoZFUjvDIqmdYZHUzrBIamdYJLUzLJLaGRZJ7a6e5pOTnAZeAl4BXq6qpY6hJI3bVGEZ/GlVvdDwdSTtEN4KSWo3bVgK+H6SJ5McXm+HJIeTLCdZvsTFKQ8naQymvRW6rarOJrkOeDTJf1bV46t3qKojwBGA3861NeXxJI3AVFcsVXV2eLwAPATc2jGUpHGbOCxJ9iR5y+XnwAeAE12DSRqvaW6FrgceSnL563yjqv6lZSpJozZxWKrqeeAPG2eRtEP442ZJ7QyLpHaGRVI7wyKpnWGR1M6wSGpnWCS1MyyS2hkWSe0Mi6R2hkVSO8MiqZ1hkdTOsEhqZ1gktTMsktoZFkntDIukdoZFUjvDIqmdYZHUzrBIamdYJLUzLJLaGRZJ7QyLpHaGRVI7wyKpnWGR1M6wSGpnWCS1MyyS2hkWSe0Mi6R2hkVSO8Miqd2mYUlyNMmFJCdWbbs2yaNJnhse9852TEljspUrlq8Bd63Zdi/wWFXdDDw2vJYkYAthqarHgRfXbD4AHBueHwPubp5L0ohN+h7L9VV1DmB4vG6jHZMcTrKcZPkSFyc8nKQxmfmbt1V1pKqWqmppF7tnfThJC2DSsJxPsg9geLzQN5KksZs0LMeBQ8PzQ8DDPeNI2gm28uPmB4H/AN6T5EySjwP3A3cmeQ64c3gtSQBcvdkOVXVwgw/d0TyLpB3ClbeS2hkWSe0Mi6R2hkVSO8MiqZ1hkdTOsEhqZ1gktdt0gZw0Nqe+/P5N9/nvP/+HTff54Nv3d4zzhuQVi6R2hkVSO8MiqZ1hkdTOsEhqZ1gktTMsktoZFkntXCCnUela/HbTtz656T7v5odbmkmv5RWLpHaGRVI7wyKpnWGR1M6wSGpnWCS1MyyS2hkWSe1cIKdRaVv89lkXv82SVyyS2hkWSe0Mi6R2hkVSO8MiqZ1hkdTOsEhqZ1gktXOBnBbG984+3fJ1XPw2f16xSGq3aViSHE1yIcmJVdvuS/LLJE8Pfz482zEljclWrli+Bty1zvYvV9X+4c8jvWNJGrNNw1JVjwMvbsMsknaIad5juSfJj4dbpb0b7ZTkcJLlJMuXuDjF4SSNxaRh+QpwE7AfOAd8caMdq+pIVS1V1dIudk94OEljMlFYqup8Vb1SVa8CXwVu7R1L0phNFJYk+1a9/AhwYqN9Jb3xbLpALsmDwO3AW5OcAT4P3J5kP1DAaeATM5xRO0DX4rcPvn1/y9fRbG0alqo6uM7mB2Ywi6QdwpW3ktoZFkntDIukdoZFUjvDIqmdYZHUzrBIauf/IKepufhNa3nFIqmdYZHUzrBIamdYJLUzLJLaGRZJ7QyLpHaGRVI7F8jpilz8pkl4xSKpnWGR1M6wSGpnWCS1MyyS2hkWSe0Mi6R2hkVSO8MiqZ0rb9/AXFWrWfGKRVI7wyKpnWGR1M6wSGpnWCS1MyyS2hkWSe0Mi6R2LpB7A7vpW5/cdJ93f/aH2zCJdppNr1iS3JjkB0lOJnk2yaeH7dcmeTTJc8Pj3tmPK2kMtnIr9DLwV1X1+8D7gU8luQW4F3isqm4GHhteS9LmYamqc1X11PD8JeAkcANwADg27HYMuHtWQ0oal9f15m2SdwLvBX4EXF9V52AlPsB1G3zO4STLSZYvcXG6aSWNwpbDkuTNwHeAz1TVr7b6eVV1pKqWqmppF7snmVHSyGwpLEl2sRKVr1fVd4fN55PsGz6+D7gwmxEljc1WfioU4AHgZFV9adWHjgOHhueHgIf7x5M0RltZx3Ib8BfAM0ku/89AnwPuB76d5OPAz4GPzmZESWOzaViq6t+BbPDhO3rH0XZy8ZtmxSX9ktoZFkntDIukdoZFUjvDIqmdYZHUzrBIamdYJLUzLJLaGRZJ7QyLpHaGRVI7wyKpnWGR1M6wSGpnWCS1MyyS2hkWSe0Mi6R2hkVSO8MiqZ1hkdTOsEhqZ1gktTMsktoZFkntUlXbd7Dkf4Cfrdr0VuCFbRugzxjndubtM8a5J535d6vqbWs3bmtYXnPwZLmqluY2wITGOLczb58xzt09s7dCktoZFknt5h2WI3M+/qTGOLczb58xzt0681zfY5G0M837ikXSDmRYJLWbW1iS3JXkp0lOJbl3XnO8HklOJ3kmydNJluc9z0aSHE1yIcmJVduuTfJokueGx73znHGtDWa+L8kvh/P9dJIPz3PGtZLcmOQHSU4meTbJp4ftC3uurzBz67mey3ssSa4C/gu4EzgDPAEcrKqfbPswr0OS08BSVS304qckfwL8GvjHqvqDYdvfAC9W1f1DyPdW1V/Pc87VNpj5PuDXVfW385xtI0n2Afuq6qkkbwGeBO4G/pIFPddXmPnPaDzX87piuRU4VVXPV9VvgG8CB+Y0y45TVY8DL67ZfAA4Njw/xso/poWxwcwLrarOVdVTw/OXgJPADSzwub7CzK3mFZYbgF+sen2GGfzlZqCA7yd5MsnheQ/zOl1fVedg5R8XcN2c59mqe5L8eLhVWphbirWSvBN4L/AjRnKu18wMjed6XmHJOtvG8HPv26rqfcCHgE8Nl++ana8ANwH7gXPAF+c7zvqSvBn4DvCZqvrVvOfZinVmbj3X8wrLGeDGVa/fAZyd0yxbVlVnh8cLwEOs3NKNxfnh/vryffaFOc+zqao6X1WvVNWrwFdZwPOdZBcr36Bfr6rvDpsX+lyvN3P3uZ5XWJ4Abk7yriTXAB8Djs9pli1Jsmd4s4ske4APACeu/FkL5ThwaHh+CHh4jrNsyeVvzsFHWLDznSTAA8DJqvrSqg8t7LneaObucz23lbfDj7P+DrgKOFpVX5jLIFuU5PdYuUoBuBr4xqLOnORB4HZWfhX+PPB54J+BbwO/A/wc+GhVLcybpRvMfDsrl+YFnAY+cfm9i0WQ5I+BfwOeAV4dNn+OlfcsFvJcX2HmgzSea5f0S2rnyltJ7QyLpHaGRVI7wyKpnWGR1M6wSGpnWCS1+z85UcTDU8cnRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def seconds_between(d1, d2):\n",
    "    d1 = datetime.strptime(d1, \"%Y-%m-%d %H:%M:%S\")\n",
    "    d2 = datetime.strptime(d2, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return (d2 - d1).seconds\n",
    "\n",
    "\n",
    "trajs = {}\n",
    "\n",
    "for t in np.unique(df.index.values):\n",
    "    traj = df.loc[t,\"lon\":\"lat\"].values\n",
    "    time = df.loc[t, \"datetime\"].values\n",
    "    \n",
    "    # get position on grid\n",
    "    state = [(np.argmin(abs(g.lat - traj[i,1])), np.argmin(abs(g.lon - traj[i,0]))) \n",
    "             for i in range(traj.shape[0])]\n",
    "    # group identical consecutive states\n",
    "    grouped_state = [(k, sum(1 for i in j)) for k,j in groupby(state)]\n",
    "    indexes = [s[1] for s in grouped_state]\n",
    "    step_length = np.zeros(len(indexes))\n",
    "    \n",
    "    # test if there is gaps in data\n",
    "    step_start = 0\n",
    "    step_end = indexes[0]\n",
    "    for i in range(len(indexes)-1):\n",
    "        step_length[i] = seconds_between( time[step_start], time[step_end])\n",
    "        step_start = np.sum(indexes[0:i+1])\n",
    "        step_end = np.sum(indexes[0:i+2])\n",
    "        \n",
    "    # create trajectory\n",
    "#     traj_new = [grouped_state[i][0] for i in range(len(grouped_state)) for j in range(int(np.round(step_length[i]/60)))]\n",
    "    \n",
    "    traj_new = [grouped_state[i][0] for i in range(len(grouped_state))]\n",
    "    \n",
    "    ## check if start = end\n",
    "    if traj_new[0] == traj_new[-1]:\n",
    "        ## continuous\n",
    "        if np.max(abs(np.array(traj_new[1:len(traj_new)]) - np.array(traj_new[0:len(traj_new)-1])))<=1:\n",
    "            trajs[t] = traj_new\n",
    "            \n",
    "#     # plot\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.gca()\n",
    "#     ax.set_aspect(\"equal\")\n",
    "#     ax.set_xticks(g.lon)\n",
    "#     ax.set_yticks(g.lat)\n",
    "#     plt.scatter(traj[:,0], traj[:,1])\n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "    # new_plt\n",
    "    grid = 0*g.grid_lon\n",
    "    for step in traj_new:\n",
    "        grid[step[0], step[1]] += 1\n",
    "    \n",
    "    plt.imshow(grid)\n",
    "    plt.savefig('./trajectory/'+t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of formatted trips  0.8305084745762712\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of formatted trips ', len(trajs) / len(np.unique(df.index.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 18)\n",
      "21\n",
      "(12, 18)\n",
      "15\n",
      "(12, 18)\n",
      "14\n",
      "(12, 18)\n",
      "7\n",
      "(12, 18)\n",
      "34\n",
      "(12, 18)\n",
      "17\n",
      "(12, 18)\n",
      "18\n",
      "(12, 18)\n",
      "10\n",
      "(12, 18)\n",
      "26\n",
      "(12, 18)\n",
      "48\n",
      "(12, 18)\n",
      "19\n",
      "(12, 18)\n",
      "11\n",
      "(12, 18)\n",
      "33\n",
      "(12, 18)\n",
      "27\n",
      "(12, 18)\n",
      "35\n",
      "(12, 18)\n",
      "15\n",
      "(12, 18)\n",
      "27\n",
      "(12, 18)\n",
      "25\n",
      "(12, 18)\n",
      "13\n",
      "(12, 18)\n",
      "15\n",
      "(12, 18)\n",
      "27\n",
      "(12, 18)\n",
      "11\n",
      "(12, 18)\n",
      "11\n",
      "(12, 18)\n",
      "19\n",
      "(12, 18)\n",
      "11\n",
      "(12, 18)\n",
      "11\n",
      "(12, 18)\n",
      "11\n",
      "(12, 18)\n",
      "11\n",
      "(12, 18)\n",
      "19\n",
      "(12, 18)\n",
      "31\n",
      "(12, 18)\n",
      "17\n",
      "(12, 18)\n",
      "33\n",
      "(12, 18)\n",
      "9\n",
      "(12, 18)\n",
      "19\n",
      "(12, 18)\n",
      "14\n",
      "(12, 18)\n",
      "10\n",
      "(12, 18)\n",
      "9\n",
      "(12, 18)\n",
      "14\n",
      "(12, 18)\n",
      "31\n",
      "(12, 18)\n",
      "27\n",
      "(12, 18)\n",
      "41\n",
      "(12, 18)\n",
      "13\n",
      "(12, 18)\n",
      "21\n",
      "(12, 18)\n",
      "34\n",
      "(12, 18)\n",
      "6\n",
      "(12, 18)\n",
      "32\n",
      "(12, 18)\n",
      "11\n",
      "(12, 18)\n",
      "19\n",
      "(12, 18)\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "## check start location\n",
    "for _,traj in trajs.items():\n",
    "    print(traj[0])\n",
    "    print(len(traj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = netCDF4.Dataset('/home/amdroy/MEGA/DATA/OCEAN/GEBCO/gebco_2019_pescadores.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation = f.variables['elevation']\n",
    "lon,lat = f.variables['lon'], f.variables['lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lon_min = min(g.lon)\n",
    "lon_max = max(g.lon)\n",
    "lat_min = min(g.lat)\n",
    "lat_max = max(g.lat)\n",
    "\n",
    "j_min = np.argmin(abs(lon[:] - lon_min))\n",
    "j_max = np.argmin(abs(lon[:] - lon_max))\n",
    "i_min = np.argmin(abs(lat[:] - lat_min))\n",
    "i_max = np.argmin(abs(lat[:] - lat_max))\n",
    "\n",
    "# plt.imshow(np.flipud(elevation[i_min:i_max, j_min:j_max]))\n",
    "# plt.show()\n",
    "\n",
    "y = lon[j_min:j_max]\n",
    "x = np.flip(lat[i_min:i_max])\n",
    "\n",
    "data = np.flipud(elevation[i_min:i_max, j_min:j_max])\n",
    "\n",
    "g.add_feature(x, y, data, 'bathy')\n",
    "g.add_feature(g.lat, g.lon, g.feature['bathy']<0, 'landmask')\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(g.feature['bathy'])\n",
    "axs[1].imshow(g.feature['landmask'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    \"\"\"\n",
    "    Grid world environment\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, length_max, height, width, start_pos):\n",
    "        \"\"\"\n",
    "            input: \n",
    "            height - idx : height of the spatial grid\n",
    "            width - idx : width of the spatial grid\n",
    "            length - idx : temporal length of a trip\n",
    "            \n",
    "            start_pos 2-tuple : coordinates within the state_space (height x width)\n",
    "            \n",
    "        \"\"\"\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.length_max = length_max\n",
    "        \n",
    "        self.start = (0, start_pos[0], start_pos[1])\n",
    "        self.end = (length_max-1, start_pos[0], start_pos[1])\n",
    "        \n",
    "        self.n_states = self.height*self.width*self.length_max\n",
    "        \n",
    "        self.actions = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "        self.n_actions = len(self.actions)\n",
    "        self.neighbors = [(0, 0),(-1, 0),(-1, 1),(0, 1),(1, 1),(1, 0),(1, -1),(0, -1),(-1, -1)]\n",
    "        self.dirs = {0: 'stay', 1: 'n', 2: 'ne', 3: 'e', 4: 'se', 5: 's', 6: 'sw', 7: 'w', 8: 'nw'}\n",
    "    \n",
    "    def get_grid_idx(self):\n",
    "        return np.array(range(self.n_states)).reshape((self.length_max, self.height, self.width))\n",
    "    \n",
    "    def get_list_state(self):\n",
    "        return [(i,j,k) for i in range(self.length_max) for j in range(self.height) for k in range(self.width)]\n",
    "    \n",
    "    def state2idx(self, state):\n",
    "        \"\"\"\n",
    "        input:\n",
    "          2d state\n",
    "        returns:\n",
    "          1d index\n",
    "        \"\"\"\n",
    "        return self.get_grid_idx()[state]\n",
    "\n",
    "    def idx2state(self, idx):\n",
    "        \"\"\"\n",
    "        input:\n",
    "          1d idx\n",
    "        returns:\n",
    "          2d state\n",
    "        \"\"\"\n",
    "        return self.get_list_state()[idx]\n",
    "           \n",
    "    def get_next_state(self, state, action):\n",
    "        \"\"\"\n",
    "        get next state with [action] on [state]\n",
    "        args\n",
    "          state     (z, y, x)\n",
    "          action    int\n",
    "        returns\n",
    "          new state\n",
    "        \"\"\"\n",
    "        if state[0] >= self.length_max-1:\n",
    "            return state\n",
    "        else :\n",
    "            inc = self.neighbors[action]\n",
    "            nei_s = (state[1] + inc[0], state[2] + inc[1])\n",
    "            if nei_s[0] >= 0 and nei_s[0] < self.height and nei_s[1] >= 0 and nei_s[1] < self.width:\n",
    "                next_state = (state[0] + 1, nei_s[0], nei_s[1])\n",
    "            else:\n",
    "                next_state = (state[0] + 1, state[1], state[2])\n",
    "            return next_state\n",
    "\n",
    "    def get_list_previous_state(self, state):\n",
    "        \"\"\"\n",
    "        args\n",
    "          state     (z, y, x)\n",
    "        returns\n",
    "          tuple\n",
    "              - previous state (z, y, x)\n",
    "              - associated action int\n",
    "        \"\"\"\n",
    "        previous = []\n",
    "        for a in self.actions:\n",
    "            inc = self.neighbors[a]\n",
    "            nei_s = (state[1] - inc[0], state[2] - inc[1])\n",
    "\n",
    "            if nei_s[0] >= 0 and nei_s[0] < self.height and nei_s[1] >= 0 and nei_s[1] < self.width:\n",
    "                previous_state = (state[0] - 1, nei_s[0], nei_s[1])\n",
    "                previous.append((previous_state,a))\n",
    "        return previous\n",
    "\n",
    "    def get_transition_mat(self):\n",
    "        \"\"\"\n",
    "        get transition dynamics of the gridworld\n",
    "        return:\n",
    "          P_a         NxN matrix in list of N_ACTIONS transition probabilities matrix - \n",
    "                        P_a[a][s0, s1] is the transition prob of \n",
    "                        landing at state s1 when taking action \n",
    "                        a at state s0\n",
    "        \"\"\"\n",
    "        P_a = [np.zeros((self.n_states, self.n_states), dtype='uint8') for i in range(self.n_actions)]\n",
    "        \n",
    "        for i in range(self.n_states):\n",
    "            si = self.idx2state(i)\n",
    "            for a in range(self.n_actions):\n",
    "                sj = self.get_next_state(si,a)\n",
    "                j = self.state2idx(sj)\n",
    "                P_a[a][i, j] = 1                \n",
    "        return P_a\n",
    "    \n",
    "def value_iteration(P_a, rewards, error=0.01, max_iter=100):\n",
    "    \"\"\"\n",
    "    static value iteration function. Perhaps the most useful function in this repo\n",
    "\n",
    "    inputs:\n",
    "    P_a         NxNxN_ACTIONS transition probabilities matrix - \n",
    "                          P_a[s0, s1, a] is the transition prob of \n",
    "                          landing at state s1 when taking action \n",
    "                          a at state s0\n",
    "    rewards     Nx1 matrix - rewards for all the states\n",
    "    gamma       float - RL discount\n",
    "    error       float - threshold for a stop\n",
    "\n",
    "    returns:\n",
    "    values    Nx1 matrix - estimated values\n",
    "    policy    Nx1 matrix - policy\n",
    "    \"\"\"\n",
    "    N_STATES, _ = np.shape(P_a[0])\n",
    "    N_ACTIONS = len(P_a)\n",
    "    \n",
    "    n = 0 \n",
    "    values = np.ones([N_STATES])* -FLOAT_MAX\n",
    "    qvalues = np.ones((N_STATES, N_ACTIONS))* -FLOAT_MAX\n",
    "    policy = np.zeros((N_STATES, N_ACTIONS))\n",
    "        \n",
    "    # estimate values\n",
    "    while True:\n",
    "        values_tmp = values.copy()\n",
    "        values[g.state2idx(g.end)] = 0 # goal\n",
    "        \n",
    "        for s in range(N_STATES):\n",
    "            qvalues[s] = [sum([P_a[a][s, s1]*(rewards[s] + values[s1]) for s1 in range(N_STATES)]) for a in range(N_ACTIONS)]\n",
    "            \n",
    "            softmax = max(qvalues[s]) + np.log(1.0 + np.exp(min(qvalues[s]) - max(qvalues[s]))) \n",
    "            values[s] = rewards[s] + softmax\n",
    "            \n",
    "            policy[s,:] = np.exp(qvalues[s]-values[s])/sum(np.exp(qvalues[s]-values[s]))\n",
    "            \n",
    "        if max([abs(values[s] - values_tmp[s]) for s in range(N_STATES)]) < error:\n",
    "            break\n",
    "        n += 1\n",
    "        # max iteration\n",
    "        if n > max_iter:\n",
    "            print(\"    WARNING: max number of iterations\", max_iter)\n",
    "            break    \n",
    "    \n",
    "    return values, policy\n",
    "\n",
    "def compute_state_visition_freq(P_a, trajs, nb_step, policy):\n",
    "    \"\"\"compute the expected states visition frequency p(s| theta, T) \n",
    "    using dynamic programming\n",
    "    inputs:\n",
    "    P_a     NxNxN_ACTIONS matrix - transition dynamics\n",
    "    gamma   float - discount factor\n",
    "    start_idx   idx of start position\n",
    "    nb_step idx - nb of step to iterate\n",
    "    policy  Nx1 vector - policy\n",
    "\n",
    "    returns:\n",
    "    p       Nx1 vector - state visitation frequencies\n",
    "    \"\"\"\n",
    "    N_STATES, _ = np.shape(P_a[0])\n",
    "    N_ACTIONS = len(P_a)\n",
    "\n",
    "    # mu[s, t] is the prob of visiting state s at time t\n",
    "    mu = np.zeros([N_STATES, nb_step]) \n",
    "\n",
    "    # start probability\n",
    "    for traj in trajs:\n",
    "        mu[traj[0], 0] += 1\n",
    "    mu[:,0] = mu[:,0]/len(trajs)\n",
    "\n",
    "    for s in range(N_STATES):\n",
    "        for t in range(nb_step-1):\n",
    "            mu[s, t+1] = sum([sum([mu[pre_s, t]*P_a[a1][pre_s, s]*policy[pre_s, a1] for a1 in range(N_ACTIONS)]) for pre_s in range(N_STATES)])\n",
    "\n",
    "    p = np.sum(mu, 1)\n",
    "    return p\n",
    "\n",
    "def maxent_irl(feat_map, P_a, trajs, lr, error, max_iter):\n",
    "    \"\"\"\n",
    "    Maximum Entropy Inverse Reinforcement Learning (Maxent IRL)\n",
    "    inputs:\n",
    "    feat_map    NxD matrix - the features for each state\n",
    "    P_a         NxNxN_ACTIONS matrix - P_a[s0, s1, a] is the transition prob of \n",
    "                                       landing at state s1 when taking action \n",
    "                                       a at state s0\n",
    "    gamma       float - RL discount factor\n",
    "    trajs       a list of demonstrations\n",
    "    lr          float - learning rate\n",
    "    n_iters     int - number of optimization steps\n",
    "    returns\n",
    "    rewards     Nx1 vector - recoverred state rewards\n",
    "    \"\"\"\n",
    "    N_STATES, _ = np.shape(P_a[0])\n",
    "    N_ACTIONS = len(P_a)\n",
    "\n",
    "    # init parameters\n",
    "    theta = np.random.uniform(size=(feat_map.shape[1]))\n",
    "    \n",
    "    # calc feature expectations\n",
    "    feat_exp = np.zeros([feat_map.shape[1]])\n",
    "    for episode in trajs:\n",
    "        for step in episode:\n",
    "            feat_exp += feat_map[step,:]\n",
    "    feat_exp = feat_exp/len(trajs)\n",
    "\n",
    "    n = 0\n",
    "    error_history = []\n",
    "    # training\n",
    "    while True:\n",
    "        n += 1\n",
    "        if n % (max_iter/20) == 0:\n",
    "            print('iteration: {}/{}'.format(n, max_iter))\n",
    "\n",
    "        # compute reward function\n",
    "        rewards = np.dot(feat_map, theta)\n",
    "\n",
    "        # compute policy\n",
    "        _, policy = value_iteration(P_a, rewards, error=0.01, max_iter=100)\n",
    "\n",
    "        # compute state visition frequences\n",
    "        svf = compute_state_visition_freq(P_a, trajs, g.length_max, policy)\n",
    "        \n",
    "        # compute gradients\n",
    "        grad = feat_exp - feat_map.T.dot(svf)\n",
    "                \n",
    "        # update params\n",
    "        theta += lr * grad\n",
    "       \n",
    "        error_history.append(sum(grad**2))\n",
    "        if sum(grad**2) < error:\n",
    "            break\n",
    "        # max iteration\n",
    "        if n > max_iter:\n",
    "            print(\"    WARNING: max number of iterations\", max_iter)\n",
    "            break \n",
    "            \n",
    "    rewards = np.dot(feat_map, theta)\n",
    "    return rewards, policy, error_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get max length\n",
    "length_max = max([len(traj) for _,traj in trajs.items()])\n",
    "\n",
    "gw = GridWorld(length_max,len(g.lat),len(g.lon),(12,18))\n",
    "\n",
    "trajectories = []\n",
    "trajectories_idx = []\n",
    "\n",
    "for _,traj in trajs.items():\n",
    "    t = [(length_max-len(traj) + i, traj[i][0], traj[i][1]) for i in range(len(traj))]\n",
    "    t_idx = [gw.state2idx(t[j]) for j in range(len(t))]\n",
    "    \n",
    "    trajectories.append(t)\n",
    "    trajectories_idx.append(t_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_map = np.array([f for _,f in g.feature.items()]).reshape(len(g.feature),gw.height*gw.width).T\n",
    "\n",
    "for t in range(gw.length_max-1):\n",
    "    feature =  np.array([f for _,f in g.feature.items()]).reshape(len(g.feature),gw.height*gw.width).T\n",
    "\n",
    "    feat_map = np.vstack([feat_map, feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "P = gw.get_transition_mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT_MAX = 1e30\n",
    "rewards, policy, error_history = maxent_irl(feat_map, P, trajectories_idx, 0.1, 0.01, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

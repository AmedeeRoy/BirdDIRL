{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRL\n",
    "\n",
    "Easy game formalism :\n",
    "\n",
    "- States = (x, t)\n",
    "- Action = (&uarr;, &darr;, &rarr;, &larr;)\n",
    "- Reward = r(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mdptoolbox\n",
    "\n",
    "FLOAT_MAX = 1e30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridworld provides a basic environment for RL agents to interact with\n",
    "\n",
    "class GridWorld:\n",
    "    \"\"\"\n",
    "    Grid world environment\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, length_max, height, width, start_pos):\n",
    "        \"\"\"\n",
    "            input: \n",
    "            height - idx : height of the spatial grid\n",
    "            width - idx : width of the spatial grid\n",
    "            length - idx : temporal length of a trip\n",
    "            \n",
    "            start_pos 2-tuple : coordinates within the state_space (height x width)\n",
    "            \n",
    "        \"\"\"\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.length_max = length_max\n",
    "        \n",
    "        self.start = (0, start_pos[0], start_pos[1])\n",
    "        self.end = (length_max-1, start_pos[0], start_pos[1])\n",
    "        \n",
    "        self.n_states = self.height*self.width*self.length_max\n",
    "        \n",
    "        self.actions = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "        self.n_actions = len(self.actions)\n",
    "        self.neighbors = [(0, 0),(-1, 0),(-1, 1),(0, 1),(1, 1),(1, 0),(1, -1),(0, -1),(-1, -1)]\n",
    "        self.dirs = {0: 'stay', 1: 'n', 2: 'ne', 3: 'e', 4: 'se', 5: 's', 6: 'sw', 7: 'w', 8: 'nw'}\n",
    "    \n",
    "    def get_grid_idx(self):\n",
    "        return np.array(range(self.n_states)).reshape((self.length_max, self.height, self.width))\n",
    "    \n",
    "    def get_list_state(self):\n",
    "        return [(i,j,k) for i in range(self.length_max) for j in range(self.height) for k in range(self.width)]\n",
    "    \n",
    "    def state2idx(self, state):\n",
    "        \"\"\"\n",
    "        input:\n",
    "          2d state\n",
    "        returns:\n",
    "          1d index\n",
    "        \"\"\"\n",
    "        return self.get_grid_idx()[state]\n",
    "\n",
    "    def idx2state(self, idx):\n",
    "        \"\"\"\n",
    "        input:\n",
    "          1d idx\n",
    "        returns:\n",
    "          2d state\n",
    "        \"\"\"\n",
    "        return self.get_list_state()[idx]\n",
    "           \n",
    "    def get_next_state(self, state, action):\n",
    "        \"\"\"\n",
    "        get next state with [action] on [state]\n",
    "        args\n",
    "          state     (z, y, x)\n",
    "          action    int\n",
    "        returns\n",
    "          new state\n",
    "        \"\"\"\n",
    "        if state[0] >= self.length_max-1:\n",
    "            return state\n",
    "        else :\n",
    "            inc = self.neighbors[action]\n",
    "            nei_s = (state[1] + inc[0], state[2] + inc[1])\n",
    "            if nei_s[0] >= 0 and nei_s[0] < self.height and nei_s[1] >= 0 and nei_s[1] < self.width:\n",
    "                next_state = (state[0] + 1, nei_s[0], nei_s[1])\n",
    "            else:\n",
    "                next_state = (state[0] + 1, state[1], state[2])\n",
    "            return next_state\n",
    "\n",
    "    def get_list_previous_state(self, state):\n",
    "        \"\"\"\n",
    "        args\n",
    "          state     (z, y, x)\n",
    "        returns\n",
    "          tuple\n",
    "              - previous state (z, y, x)\n",
    "              - associated action int\n",
    "        \"\"\"\n",
    "        previous = []\n",
    "        for a in self.actions:\n",
    "            inc = self.neighbors[a]\n",
    "            nei_s = (state[1] - inc[0], state[2] - inc[1])\n",
    "\n",
    "            if nei_s[0] >= 0 and nei_s[0] < self.height and nei_s[1] >= 0 and nei_s[1] < self.width:\n",
    "                previous_state = (state[0] - 1, nei_s[0], nei_s[1])\n",
    "                previous.append((previous_state,a))\n",
    "        return previous\n",
    "\n",
    "    def get_transition_mat(self):\n",
    "        \"\"\"\n",
    "        get transition dynamics of the gridworld\n",
    "        return:\n",
    "          P_a         NxNxN_ACTIONS transition probabilities matrix - \n",
    "                        P_a[s0, s1, a] is the transition prob of \n",
    "                        landing at state s1 when taking action \n",
    "                        a at state s0\n",
    "        \"\"\"\n",
    "        P_a = np.zeros((self.n_states, self.n_states, self.n_actions))\n",
    "        \n",
    "        for i in range(self.n_states):\n",
    "            si = self.idx2state(i)\n",
    "            for a in range(self.n_actions):\n",
    "                sj = self.get_next_state(si,a)\n",
    "                j = self.state2idx(sj)\n",
    "                P_a[i, j, a] = 1                \n",
    "        return P_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = GridWorld(5,3,4,(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]],\n",
       "\n",
       "       [[24, 25, 26, 27],\n",
       "        [28, 29, 30, 31],\n",
       "        [32, 33, 34, 35]],\n",
       "\n",
       "       [[36, 37, 38, 39],\n",
       "        [40, 41, 42, 43],\n",
       "        [44, 45, 46, 47]],\n",
       "\n",
       "       [[48, 49, 50, 51],\n",
       "        [52, 53, 54, 55],\n",
       "        [56, 57, 58, 59]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_grid_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(P_a, rewards, error=0.01, max_iter=100):\n",
    "    \"\"\"\n",
    "    static value iteration function. Perhaps the most useful function in this repo\n",
    "\n",
    "    inputs:\n",
    "    P_a         NxNxN_ACTIONS transition probabilities matrix - \n",
    "                          P_a[s0, s1, a] is the transition prob of \n",
    "                          landing at state s1 when taking action \n",
    "                          a at state s0\n",
    "    rewards     Nx1 matrix - rewards for all the states\n",
    "    gamma       float - RL discount\n",
    "    error       float - threshold for a stop\n",
    "\n",
    "    returns:\n",
    "    values    Nx1 matrix - estimated values\n",
    "    policy    Nx1 matrix - policy\n",
    "    \"\"\"\n",
    "    N_STATES, _, N_ACTIONS = np.shape(P_a)\n",
    "    n = 0 \n",
    "    values = np.ones([N_STATES])* -FLOAT_MAX\n",
    "    qvalues = np.ones((N_STATES, N_ACTIONS))* -FLOAT_MAX\n",
    "    policy = np.zeros((N_STATES, N_ACTIONS))\n",
    "        \n",
    "    # estimate values\n",
    "    while True:\n",
    "        values_tmp = values.copy()\n",
    "        values[g.state2idx(g.end)] = 0 # goal\n",
    "        \n",
    "        for s in range(N_STATES):\n",
    "            qvalues[s] = [sum([P_a[s, s1, a]*(rewards[s] + values[s1]) for s1 in range(N_STATES)]) for a in range(N_ACTIONS)]\n",
    "            \n",
    "            softmax = max(qvalues[s]) + np.log(1.0 + np.exp(min(qvalues[s]) - max(qvalues[s]))) \n",
    "            values[s] = rewards[s] + softmax\n",
    "            \n",
    "            policy[s,:] = np.exp(qvalues[s]-values[s])/sum(np.exp(qvalues[s]-values[s]))\n",
    "            \n",
    "        if max([abs(values[s] - values_tmp[s]) for s in range(N_STATES)]) < error:\n",
    "            break\n",
    "        n += 1\n",
    "        # max iteration\n",
    "        if n > max_iter:\n",
    "            print(\"    WARNING: max number of iterations\", max_iter)\n",
    "            break    \n",
    "    \n",
    "    return values, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.46661996e+00, -1.52591661e-01, -1.58766669e+00,\n",
       "         -1.91318478e+00],\n",
       "        [-1.01242706e+00, -4.33060086e-02, -1.35200989e+00,\n",
       "         -1.05052820e+00],\n",
       "        [-1.20096265e+00, -1.27595129e-01, -1.89479857e+00,\n",
       "         -1.76361162e+00]],\n",
       "\n",
       "       [[-7.24764053e-01, -1.39038292e+00, -1.32574651e+00,\n",
       "         -2.26107292e+00],\n",
       "        [-1.22785608e-01, -1.44003294e+00, -1.19979375e+00,\n",
       "         -1.68175108e+00],\n",
       "        [-1.11506318e+00, -1.92806850e+00, -1.66445005e+00,\n",
       "         -2.61931343e+00]],\n",
       "\n",
       "       [[-6.84147060e-01, -1.84772682e+00, -1.50100507e+00,\n",
       "         -1.76659398e+00],\n",
       "        [-2.31850408e-01, -5.86872107e-01, -1.08668789e+00,\n",
       "         -1.40568990e+00],\n",
       "        [-1.56537054e+00, -5.49035904e-01, -1.92236743e+00,\n",
       "         -1.72261046e+00]],\n",
       "\n",
       "       [[-1.38574013e+00, -6.55353981e-01, -1.30698620e+00,\n",
       "         -1.00000000e+30],\n",
       "        [-3.04708461e-01, -1.12242464e+00, -2.59031559e-01,\n",
       "         -1.00000000e+30],\n",
       "        [-1.80846441e-02, -1.46464269e+00, -8.25265462e-01,\n",
       "         -1.00000000e+30]],\n",
       "\n",
       "       [[-1.00000000e+30, -1.00000000e+30, -1.00000000e+30,\n",
       "         -1.00000000e+30],\n",
       "        [-1.00000000e+30,  1.32822495e-01, -1.00000000e+30,\n",
       "         -1.00000000e+30],\n",
       "        [-1.00000000e+30, -1.00000000e+30, -1.00000000e+30,\n",
       "         -1.00000000e+30]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = g.get_transition_mat()\n",
    "R = -np.random.random((g.n_states, 1))\n",
    "\n",
    "values, policy = value_iteration(P, R, 0.01, 100)\n",
    "\n",
    "values.reshape((g.length_max, g.height, g.width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1132664 , 0.1132664 , 0.1132664 , 0.05821388, 0.05539413,\n",
       "        0.20679357, 0.1132664 , 0.1132664 , 0.1132664 ],\n",
       "       [0.07857745, 0.07857745, 0.07857745, 0.08382415, 0.09507575,\n",
       "        0.07477135, 0.27913125, 0.1528877 , 0.07857745],\n",
       "       [0.12412236, 0.12412236, 0.12412236, 0.04871278, 0.08694391,\n",
       "        0.14078312, 0.11071744, 0.11635332, 0.12412236],\n",
       "       [0.07562616, 0.07562616, 0.07562616, 0.07562616, 0.07562616,\n",
       "        0.13497965, 0.21856455, 0.19269885, 0.07562616],\n",
       "       [0.17754846, 0.09724807, 0.04998117, 0.0475602 , 0.02919393,\n",
       "        0.06582278, 0.17754846, 0.17754846, 0.17754846],\n",
       "       [0.07681554, 0.0807257 , 0.08611584, 0.09767505, 0.06137422,\n",
       "        0.04715176, 0.10631185, 0.28676249, 0.15706754],\n",
       "       [0.17208514, 0.15171998, 0.05954368, 0.10627521, 0.04161537,\n",
       "        0.10812988, 0.08307257, 0.13533459, 0.14222356],\n",
       "       [0.11091189, 0.06214151, 0.11091189, 0.11091189, 0.11091189,\n",
       "        0.04343101, 0.11284748, 0.17959305, 0.15833938],\n",
       "       [0.10138447, 0.27347153, 0.07325527, 0.04496636, 0.10138447,\n",
       "        0.10138447, 0.10138447, 0.10138447, 0.10138447],\n",
       "       [0.05767474, 0.09395865, 0.11947343, 0.07507125, 0.05767474,\n",
       "        0.05767474, 0.05767474, 0.13003772, 0.35075998],\n",
       "       [0.11137049, 0.17724247, 0.10946024, 0.04286257, 0.11137049,\n",
       "        0.11137049, 0.11137049, 0.08556223, 0.13939052],\n",
       "       [0.06541421, 0.16705145, 0.06541421, 0.06541421, 0.06541421,\n",
       "        0.06541421, 0.06541421, 0.16996676, 0.27049651],\n",
       "       [0.11127868, 0.11127868, 0.11127868, 0.03475967, 0.12264728,\n",
       "        0.17492098, 0.11127868, 0.11127868, 0.11127868],\n",
       "       [0.0517678 , 0.0517678 , 0.0517678 , 0.07322157, 0.11080892,\n",
       "        0.18265937, 0.26051091, 0.16572803, 0.0517678 ],\n",
       "       [0.09450268, 0.09450268, 0.09450268, 0.07246034, 0.10395347,\n",
       "        0.14301441, 0.23574747, 0.06681359, 0.09450268],\n",
       "       [0.09334874, 0.09334874, 0.09334874, 0.09334874, 0.09334874,\n",
       "        0.13392052, 0.1842417 , 0.12174532, 0.09334874],\n",
       "       [0.15319135, 0.09745504, 0.03044164, 0.10741138, 0.11155328,\n",
       "        0.04037326, 0.15319135, 0.15319135, 0.15319135],\n",
       "       [0.1586823 , 0.04497242, 0.06361003, 0.09626341, 0.04173786,\n",
       "        0.16480126, 0.05964472, 0.22631453, 0.14397348],\n",
       "       [0.13012468, 0.08598526, 0.06592956, 0.09458426, 0.0688941 ,\n",
       "        0.05641943, 0.22277116, 0.21449981, 0.06079175],\n",
       "       [0.12038368, 0.08391294, 0.12038368, 0.12038368, 0.12038368,\n",
       "        0.0876861 , 0.07180876, 0.16561834, 0.10943916],\n",
       "       [0.06571216, 0.24933668, 0.17482447, 0.18156589, 0.06571216,\n",
       "        0.06571216, 0.06571216, 0.06571216, 0.06571216],\n",
       "       [0.13270648, 0.12777918, 0.07751627, 0.03360948, 0.13270648,\n",
       "        0.13270648, 0.13270648, 0.04802901, 0.18224014],\n",
       "       [0.0589821 , 0.13603518, 0.09888044, 0.07202339, 0.0589821 ,\n",
       "        0.0589821 , 0.0589821 , 0.23288982, 0.22424278],\n",
       "       [0.09920057, 0.13619182, 0.09920057, 0.09920057, 0.09920057,\n",
       "        0.09920057, 0.09920057, 0.0812383 , 0.18736645],\n",
       "       [0.08113697, 0.08113697, 0.08113697, 0.16843077, 0.10557844,\n",
       "        0.23916898, 0.08113697, 0.08113697, 0.08113697],\n",
       "       [0.11714972, 0.11714972, 0.11714972, 0.06105777, 0.1741253 ,\n",
       "        0.07343364, 0.16635071, 0.05643371, 0.11714972],\n",
       "       [0.10026899, 0.10026899, 0.10026899, 0.        , 0.        ,\n",
       "        0.28594833, 0.12059261, 0.1923831 , 0.10026899],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.74038194, 0.25961806, 0.        ],\n",
       "       [0.14024562, 0.04757768, 0.09876565, 0.06190984, 0.04396796,\n",
       "        0.18679638, 0.14024562, 0.14024562, 0.14024562],\n",
       "       [0.07191528, 0.11472746, 0.05979531, 0.17052499, 0.09680009,\n",
       "        0.05107375, 0.21698512, 0.16291115, 0.05526685],\n",
       "       [0.3019013 , 0.10586297, 0.        , 0.        , 0.        ,\n",
       "        0.17137707, 0.09042213, 0.12732044, 0.2031161 ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2959158 , 0.52129123, 0.18279297],\n",
       "       [0.13665678, 0.1026011 , 0.04529209, 0.03216614, 0.13665678,\n",
       "        0.13665678, 0.13665678, 0.13665678, 0.13665678],\n",
       "       [0.05530865, 0.07787829, 0.18466444, 0.10482648, 0.05530865,\n",
       "        0.05530865, 0.05530865, 0.23497691, 0.17641928],\n",
       "       [0.14220368, 0.25050886, 0.        , 0.        , 0.14220368,\n",
       "        0.14220368, 0.14220368, 0.07502964, 0.10564678],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.36210629, 0.63789371],\n",
       "       [0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        ],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111],\n",
       "       [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111,\n",
       "        0.11111111, 0.11111111, 0.11111111, 0.11111111]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_state_visition_freq(P_a, start_idx, nb_step, policy):\n",
    "    \"\"\"compute the expected states visition frequency p(s| theta, T) \n",
    "    using dynamic programming\n",
    "    inputs:\n",
    "    P_a     NxNxN_ACTIONS matrix - transition dynamics\n",
    "    gamma   float - discount factor\n",
    "    start_idx   idx of start position\n",
    "    nb_step idx - nb of step to iterate\n",
    "    policy  Nx1 vector - policy\n",
    "\n",
    "    returns:\n",
    "    p       Nx1 vector - state visitation frequencies\n",
    "    \"\"\"\n",
    "    N_STATES, _, N_ACTIONS = np.shape(P_a)\n",
    "\n",
    "    # mu[s, t] is the prob of visiting state s at time t\n",
    "    mu = np.zeros([N_STATES, nb_step]) \n",
    "\n",
    "    mu[start_idx, 0] = 1\n",
    "    for s in range(N_STATES):\n",
    "        for t in range(nb_step-1):\n",
    "            mu[s, t+1] = sum([sum([mu[pre_s, t]*P_a[pre_s, s, a1]*policy[pre_s, a1] for a1 in range(N_ACTIONS)]) for pre_s in range(N_STATES)])\n",
    "\n",
    "    p = np.sum(mu, 1)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]],\n",
       "\n",
       "       [[0.15706754, 0.0807257 , 0.08611584, 0.        ],\n",
       "        [0.28676249, 0.07681554, 0.09767505, 0.        ],\n",
       "        [0.10631185, 0.04715176, 0.06137422, 0.        ]],\n",
       "\n",
       "       [[0.15725397, 0.04605123, 0.05174843, 0.01267966],\n",
       "        [0.27670733, 0.15662656, 0.05336948, 0.02425927],\n",
       "        [0.06033972, 0.12503319, 0.02478155, 0.01114961]],\n",
       "\n",
       "       [[0.10097485, 0.11416023, 0.04630851, 0.        ],\n",
       "        [0.2542643 , 0.07650297, 0.12408051, 0.        ],\n",
       "        [0.16452846, 0.05645346, 0.06272672, 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        ]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svf = compute_state_visition_freq(P, g.state2idx((0,1,1)), g.length_max, policy)\n",
    "svf.reshape((g.length_max, g.height, g.width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]],\n",
       "\n",
       "       [[24, 25, 26, 27],\n",
       "        [28, 29, 30, 31],\n",
       "        [32, 33, 34, 35]],\n",
       "\n",
       "       [[36, 37, 38, 39],\n",
       "        [40, 41, 42, 43],\n",
       "        [44, 45, 46, 47]],\n",
       "\n",
       "       [[48, 49, 50, 51],\n",
       "        [52, 53, 54, 55],\n",
       "        [56, 57, 58, 59]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.get_grid_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.],\n",
       "       [ 0., 12.,  4.,  0.],\n",
       "       [ 0.,  7.,  7.,  0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create expert trajectories\n",
    "\n",
    "traj_1 = [5, 18, 33, 46, 53]\n",
    "traj_2 = [5, 22, 30, 45, 53]\n",
    "traj_3 = [5, 21, 34, 45, 53]\n",
    "traj_4 = [5, 21, 33, 45, 53]\n",
    "traj_5 = [5, 22, 34, 42, 53]\n",
    "traj_6 = [5, 22, 34, 42, 53]\n",
    "\n",
    "trajs = [traj_1, traj_2, traj_3, traj_4, traj_5, traj_6]\n",
    "\n",
    "\n",
    "freq = np.zeros((3,4))\n",
    "for traj in trajs:\n",
    "    for idx in traj:\n",
    "        state = g.idx2state(idx)\n",
    "        freq[state[1], state[2]] += 1\n",
    "        \n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feat_map\n",
    "\n",
    "map_mask = [[-1, -1, -1, 0],\n",
    "            [-1, 0, 0, 0],\n",
    "            [-1, 0, 0, 0]]\n",
    "\n",
    "map_dist = [[-0.5, -0.5, -0.5, -1],\n",
    "            [-0.5, 0, -0.5, -1],\n",
    "            [-0.5, -0.5, -0.5, -1]]\n",
    "\n",
    "map_gradv = [[0, 0, 0, 0],\n",
    "            [-0.5, -0.5, -0.5, -0.5],\n",
    "            [-1, -1, -1, -1]]\n",
    "\n",
    "map_gradh = [[0, -0.3, -0.6, -0.9],\n",
    "            [0, -0.3, -0.6, -0.9],\n",
    "            [0, -0.3, -0.6, -0.9]]\n",
    "\n",
    "map_const = [[0, 0, 0, 0],\n",
    "            [0, 0, 0, 0],\n",
    "            [0, 0, 0, 0]]\n",
    "\n",
    "\n",
    "\n",
    "feat_map = np.array([map_mask, map_dist, map_gradv, map_gradh, map_const]).reshape(5,12).T\n",
    "for t in range(g.length_max-1):\n",
    "    feature =  np.array([map_mask, map_dist, map_gradv, map_gradh, map_const]).reshape(5,12).T\n",
    "    feature[:,4] -= 0.1*(t+1)\n",
    "    \n",
    "    feat_map = np.vstack([feat_map, feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. , -0.5,  0. ,  0. ,  0. ],\n",
       "       [-1. , -0.5,  0. , -0.3,  0. ],\n",
       "       [-1. , -0.5,  0. , -0.6,  0. ],\n",
       "       [ 0. , -1. ,  0. , -0.9,  0. ],\n",
       "       [-1. , -0.5, -0.5,  0. ,  0. ],\n",
       "       [ 0. ,  0. , -0.5, -0.3,  0. ],\n",
       "       [ 0. , -0.5, -0.5, -0.6,  0. ],\n",
       "       [ 0. , -1. , -0.5, -0.9,  0. ],\n",
       "       [-1. , -0.5, -1. ,  0. ,  0. ],\n",
       "       [ 0. , -0.5, -1. , -0.3,  0. ],\n",
       "       [ 0. , -0.5, -1. , -0.6,  0. ],\n",
       "       [ 0. , -1. , -1. , -0.9,  0. ],\n",
       "       [-1. , -0.5,  0. ,  0. , -0.1],\n",
       "       [-1. , -0.5,  0. , -0.3, -0.1],\n",
       "       [-1. , -0.5,  0. , -0.6, -0.1],\n",
       "       [ 0. , -1. ,  0. , -0.9, -0.1],\n",
       "       [-1. , -0.5, -0.5,  0. , -0.1],\n",
       "       [ 0. ,  0. , -0.5, -0.3, -0.1],\n",
       "       [ 0. , -0.5, -0.5, -0.6, -0.1],\n",
       "       [ 0. , -1. , -0.5, -0.9, -0.1],\n",
       "       [-1. , -0.5, -1. ,  0. , -0.1],\n",
       "       [ 0. , -0.5, -1. , -0.3, -0.1],\n",
       "       [ 0. , -0.5, -1. , -0.6, -0.1],\n",
       "       [ 0. , -1. , -1. , -0.9, -0.1],\n",
       "       [-1. , -0.5,  0. ,  0. , -0.2],\n",
       "       [-1. , -0.5,  0. , -0.3, -0.2],\n",
       "       [-1. , -0.5,  0. , -0.6, -0.2],\n",
       "       [ 0. , -1. ,  0. , -0.9, -0.2],\n",
       "       [-1. , -0.5, -0.5,  0. , -0.2],\n",
       "       [ 0. ,  0. , -0.5, -0.3, -0.2],\n",
       "       [ 0. , -0.5, -0.5, -0.6, -0.2],\n",
       "       [ 0. , -1. , -0.5, -0.9, -0.2],\n",
       "       [-1. , -0.5, -1. ,  0. , -0.2],\n",
       "       [ 0. , -0.5, -1. , -0.3, -0.2],\n",
       "       [ 0. , -0.5, -1. , -0.6, -0.2],\n",
       "       [ 0. , -1. , -1. , -0.9, -0.2],\n",
       "       [-1. , -0.5,  0. ,  0. , -0.3],\n",
       "       [-1. , -0.5,  0. , -0.3, -0.3],\n",
       "       [-1. , -0.5,  0. , -0.6, -0.3],\n",
       "       [ 0. , -1. ,  0. , -0.9, -0.3],\n",
       "       [-1. , -0.5, -0.5,  0. , -0.3],\n",
       "       [ 0. ,  0. , -0.5, -0.3, -0.3],\n",
       "       [ 0. , -0.5, -0.5, -0.6, -0.3],\n",
       "       [ 0. , -1. , -0.5, -0.9, -0.3],\n",
       "       [-1. , -0.5, -1. ,  0. , -0.3],\n",
       "       [ 0. , -0.5, -1. , -0.3, -0.3],\n",
       "       [ 0. , -0.5, -1. , -0.6, -0.3],\n",
       "       [ 0. , -1. , -1. , -0.9, -0.3],\n",
       "       [-1. , -0.5,  0. ,  0. , -0.4],\n",
       "       [-1. , -0.5,  0. , -0.3, -0.4],\n",
       "       [-1. , -0.5,  0. , -0.6, -0.4],\n",
       "       [ 0. , -1. ,  0. , -0.9, -0.4],\n",
       "       [-1. , -0.5, -0.5,  0. , -0.4],\n",
       "       [ 0. ,  0. , -0.5, -0.3, -0.4],\n",
       "       [ 0. , -0.5, -0.5, -0.6, -0.4],\n",
       "       [ 0. , -1. , -0.5, -0.9, -0.4],\n",
       "       [-1. , -0.5, -1. ,  0. , -0.4],\n",
       "       [ 0. , -0.5, -1. , -0.3, -0.4],\n",
       "       [ 0. , -0.5, -1. , -0.6, -0.4],\n",
       "       [ 0. , -1. , -1. , -0.9, -0.4]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxent_irl(feat_map, P_a, trajs, lr, error, max_iter):\n",
    "    \"\"\"\n",
    "    Maximum Entropy Inverse Reinforcement Learning (Maxent IRL)\n",
    "    inputs:\n",
    "    feat_map    NxD matrix - the features for each state\n",
    "    P_a         NxNxN_ACTIONS matrix - P_a[s0, s1, a] is the transition prob of \n",
    "                                       landing at state s1 when taking action \n",
    "                                       a at state s0\n",
    "    gamma       float - RL discount factor\n",
    "    trajs       a list of demonstrations\n",
    "    lr          float - learning rate\n",
    "    n_iters     int - number of optimization steps\n",
    "    returns\n",
    "    rewards     Nx1 vector - recoverred state rewards\n",
    "    \"\"\"\n",
    "    N_STATES, _, N_ACTIONS = np.shape(P_a)\n",
    "\n",
    "    # init parameters\n",
    "    theta = np.random.uniform(size=(feat_map.shape[1]))\n",
    "    \n",
    "    # calc feature expectations\n",
    "    feat_exp = np.zeros([feat_map.shape[1]])\n",
    "    for episode in trajs:\n",
    "        for step in episode:\n",
    "            feat_exp += feat_map[step,:]\n",
    "    feat_exp = feat_exp/len(trajs)\n",
    "\n",
    "    n = 0\n",
    "    error_history = []\n",
    "    # training\n",
    "    while True:\n",
    "        n += 1\n",
    "        if n % (max_iter/20) == 0:\n",
    "            print('iteration: {}/{}'.format(n, max_iter))\n",
    "\n",
    "        # compute reward function\n",
    "        rewards = np.dot(feat_map, theta)\n",
    "\n",
    "        # compute policy\n",
    "        _, policy = value_iteration(P_a, rewards, error=0.01, max_iter=100)\n",
    "\n",
    "        # compute state visition frequences\n",
    "        svf = compute_state_visition_freq(P_a, g.state2idx((0,1,1)), g.length_max, policy)\n",
    "        \n",
    "        # compute gradients\n",
    "        grad = feat_exp - feat_map.T.dot(svf)\n",
    "                \n",
    "        # update params\n",
    "        theta += lr * grad\n",
    "       \n",
    "        error_history.append(sum(grad**2))\n",
    "        if sum(grad**2) < error:\n",
    "            break\n",
    "        # max iteration\n",
    "        if n > max_iter:\n",
    "            print(\"    WARNING: max number of iterations\", max_iter)\n",
    "            break \n",
    "            \n",
    "    rewards = np.dot(feat_map, theta)\n",
    "    return rewards, policy, error_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 5/100\n",
      "iteration: 10/100\n",
      "iteration: 15/100\n",
      "iteration: 20/100\n",
      "iteration: 25/100\n",
      "iteration: 30/100\n",
      "iteration: 35/100\n",
      "iteration: 40/100\n"
     ]
    }
   ],
   "source": [
    "rewards, policy, error_history = maxent_irl(feat_map, P, trajs, 0.1, 0.01, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcf18194610>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(error_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards_grid = rewards.reshape((g.length_max, g.height, g.width))\n",
    "rewards_grid = rewards_grid[0,:,:]\n",
    "\n",
    "# Map\n",
    "\n",
    "plt.imshow(rewards_grid);\n",
    "plt.title('Rewards')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.13195329, -1.06192749, -0.99190169,  0.22719791],\n",
       "        [-0.7380773 ,  0.46390179,  0.54248785,  0.6210739 ],\n",
       "        [-0.34420131,  0.86633804,  0.93636384,  1.01494989]],\n",
       "\n",
       "       [[-1.20625899, -1.13623319, -1.06620738,  0.15289222],\n",
       "        [-0.812383  ,  0.3895961 ,  0.46818215,  0.54676821],\n",
       "        [-0.41850701,  0.79203234,  0.86205814,  0.9406442 ]],\n",
       "\n",
       "       [[-1.28056468, -1.21053888, -1.14051308,  0.07858652],\n",
       "        [-0.88668869,  0.3152904 ,  0.39387646,  0.47246251],\n",
       "        [-0.4928127 ,  0.71772665,  0.78775245,  0.8663385 ]],\n",
       "\n",
       "       [[-1.35487038, -1.28484457, -1.21481877,  0.00428083],\n",
       "        [-0.96099438,  0.24098471,  0.31957076,  0.39815682],\n",
       "        [-0.56711839,  0.64342095,  0.71344676,  0.79203281]],\n",
       "\n",
       "       [[-1.42917607, -1.35915027, -1.28912447, -0.07002487],\n",
       "        [-1.03530008,  0.16667902,  0.24526507,  0.32385113],\n",
       "        [-0.64142409,  0.56911526,  0.63914106,  0.71772712]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards.reshape((g.length_max, g.height, g.width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_demonstrations(g, policy, n_trajs=10, len_traj=5):\n",
    "    \"\"\"gatheres expert demonstrations\n",
    "    inputs:\n",
    "    policy      Nx1 matrix\n",
    "    n_trajs     int - number of trajectories to generate\n",
    "    rand_start  bool - randomly picking start position or not\n",
    "    start_pos   2x1 list - set start position, default [0,0]\n",
    "    returns:\n",
    "    trajs       a list of trajectories - each element in the list is a list of Steps representing an episode\n",
    "    \"\"\"\n",
    "\n",
    "    trajs = []\n",
    "    for i in range(n_trajs):\n",
    "        \n",
    "        episode = []\n",
    "        state = (0,1,1)\n",
    "        idx = g.state2idx(state)\n",
    "        episode.append(idx)\n",
    "        \n",
    "        # while not is_done:\n",
    "        for _ in range(len_traj-1):\n",
    "\n",
    "            act = np.random.choice(g.n_actions, p= policy[idx,:])\n",
    "            next_state = g.get_next_state(state, act)\n",
    "            next_idx = g.state2idx(next_state)\n",
    "            episode.append(next_idx)\n",
    "            state = next_state\n",
    "            idx = next_idx\n",
    "            \n",
    "        trajs.append(episode)\n",
    "    return trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 18, 29, 41, 53],\n",
       " [5, 18, 34, 46, 53],\n",
       " [5, 22, 30, 46, 53],\n",
       " [5, 22, 34, 45, 53],\n",
       " [5, 21, 33, 45, 53],\n",
       " [5, 18, 31, 46, 53],\n",
       " [5, 18, 34, 46, 53],\n",
       " [5, 22, 30, 46, 53],\n",
       " [5, 17, 34, 41, 53],\n",
       " [5, 22, 35, 42, 53],\n",
       " [5, 21, 30, 41, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 21, 33, 45, 53],\n",
       " [5, 22, 33, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 18, 35, 46, 53],\n",
       " [5, 21, 33, 41, 53],\n",
       " [5, 17, 34, 46, 53],\n",
       " [5, 18, 35, 46, 53],\n",
       " [5, 21, 30, 46, 53],\n",
       " [5, 22, 33, 41, 53],\n",
       " [5, 22, 34, 42, 53],\n",
       " [5, 22, 34, 42, 53],\n",
       " [5, 17, 34, 46, 53],\n",
       " [5, 21, 33, 45, 53],\n",
       " [5, 22, 34, 45, 53],\n",
       " [5, 22, 33, 45, 53],\n",
       " [5, 21, 30, 46, 53],\n",
       " [5, 22, 30, 45, 53],\n",
       " [5, 18, 30, 46, 53],\n",
       " [5, 18, 33, 45, 53],\n",
       " [5, 22, 34, 41, 53],\n",
       " [5, 21, 34, 46, 53],\n",
       " [5, 16, 33, 45, 53],\n",
       " [5, 21, 33, 42, 53],\n",
       " [5, 16, 29, 45, 53],\n",
       " [5, 18, 34, 46, 53],\n",
       " [5, 21, 30, 45, 53],\n",
       " [5, 22, 29, 41, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 21, 29, 46, 53],\n",
       " [5, 21, 30, 46, 53],\n",
       " [5, 18, 34, 46, 53],\n",
       " [5, 21, 33, 46, 53],\n",
       " [5, 18, 33, 46, 53],\n",
       " [5, 22, 34, 46, 53],\n",
       " [5, 22, 35, 42, 53],\n",
       " [5, 22, 34, 46, 53]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajs = generate_demonstrations(g, policy, 50, 5)\n",
    "trajs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.],\n",
       "       [  2., 114.,  25.,   1.],\n",
       "       [  0.,  36.,  68.,   4.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = np.zeros((3,4))\n",
    "for traj in trajs:\n",
    "    for idx in traj:\n",
    "        state = g.idx2state(idx)\n",
    "        freq[state[1], state[2]] += 1\n",
    "        \n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
